{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ¨¡çµ„ 3: ä¼æ¥­ç´šå“è³ªæ§åˆ¶èˆ‡ç›£æ§ç³»çµ±\n",
    "## Module 3: Enterprise Quality Control & Monitoring Systems\n",
    "\n",
    "> **æ•™å­¸ç›®æ¨™**: å»ºç«‹å¤šç¶­åº¦å“è³ªè©•ä¼°æ¡†æ¶ã€å¯¦ä½œè‡ªå‹•åŒ–å“è³ªç›£æ§ã€è¨­è¨ˆç•°å¸¸æª¢æ¸¬èˆ‡è­¦å ±ç³»çµ±\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š å­¸ç¿’æˆæœ (Learning Outcomes)\n",
    "\n",
    "å®Œæˆæœ¬æ¨¡çµ„å¾Œï¼Œæ‚¨å°‡èƒ½å¤ ï¼š\n",
    "1. **è¨­è¨ˆå¤šç¶­åº¦å“è³ªæ¨¡å‹** - åŸºæ–¼ ISO 25012 æ¨™æº–çš„å…¨é¢è©•ä¼°æ¡†æ¶\n",
    "2. **å¯¦ä½œè‡ªå‹•åŒ–å“è³ªç›£æ§** - å³æ™‚æª¢æ¸¬å“è³ªè®ŠåŒ–èˆ‡ç•°å¸¸\n",
    "3. **å»ºç«‹å“è³ªæ²»ç†æµç¨‹** - åŒ…å«å¯©æ ¸ã€ä¿®æ­£ã€ç‰ˆæœ¬æ§åˆ¶\n",
    "4. **è¨­è¨ˆç•°å¸¸æª¢æ¸¬ç³»çµ±** - æ©Ÿå™¨å­¸ç¿’é©…å‹•çš„å“è³ªç•°å¸¸è­˜åˆ¥\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ (Core Concepts)\n",
    "\n",
    "### 1. è³‡æ–™å“è³ªç¶­åº¦ (ISO 25012)\n",
    "- **æº–ç¢ºæ€§ (Accuracy)**: è³‡æ–™èˆ‡çœŸå¯¦å€¼çš„ç¬¦åˆç¨‹åº¦\n",
    "- **å®Œæ•´æ€§ (Completeness)**: å¿…è¦è³‡è¨Šçš„å®Œæ•´ç¨‹åº¦\n",
    "- **ä¸€è‡´æ€§ (Consistency)**: è³‡æ–™æ ¼å¼èˆ‡è¦å‰‡çš„ä¸€è‡´æ€§\n",
    "- **æ™‚æ•ˆæ€§ (Currency)**: è³‡æ–™çš„æ–°é®®åº¦èˆ‡åŠæ™‚æ€§\n",
    "- **å¯ç†è§£æ€§ (Understandability)**: è³‡æ–™çš„å¯è®€æ€§èˆ‡æ¸…æ™°åº¦\n",
    "- **å¯è¿½æº¯æ€§ (Traceability)**: è³‡æ–™ä¾†æºèˆ‡è™•ç†æ­·ç¨‹çš„è¿½è¹¤\n",
    "\n",
    "### 2. å“è³ªæ§åˆ¶ç­–ç•¥\n",
    "- **é é˜²æ€§æ§åˆ¶**: åœ¨è³‡æ–™æ”å–éšæ®µçš„å“è³ªæª¢æŸ¥\n",
    "- **æª¢æ¸¬æ€§æ§åˆ¶**: è™•ç†éç¨‹ä¸­çš„å“è³ªç›£æ§\n",
    "- **ä¿®æ­£æ€§æ§åˆ¶**: ç™¼ç¾å•é¡Œå¾Œçš„è‡ªå‹•ä¿®å¾©\n",
    "- **æŒçºŒæ”¹é€²**: åŸºæ–¼æ­·å²è³‡æ–™çš„å“è³ªå„ªåŒ–\n",
    "\n",
    "### 3. ç•°å¸¸æª¢æ¸¬æŠ€è¡“\n",
    "- **çµ±è¨ˆç•°å¸¸æª¢æ¸¬**: åŸºæ–¼åˆ†ä½ˆå’Œé–¾å€¼çš„æª¢æ¸¬\n",
    "- **æ©Ÿå™¨å­¸ç¿’ç•°å¸¸æª¢æ¸¬**: ä½¿ç”¨ Isolation Forestã€One-Class SVM\n",
    "- **æ™‚é–“åºåˆ—ç•°å¸¸æª¢æ¸¬**: æª¢æ¸¬å“è³ªæŒ‡æ¨™çš„æ™‚é–“è®ŠåŒ–\n",
    "- **å¤šè®Šé‡ç•°å¸¸æª¢æ¸¬**: è€ƒæ…®å¤šå€‹å“è³ªç¶­åº¦çš„é—œè¯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ ç’°å¢ƒè¨­å®šèˆ‡ä¾è³´å®‰è£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (1.7.2)\n",
      "Requirement already satisfied: pandas in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (3.10.6)\n",
      "Requirement already satisfied: seaborn in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: plotly in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (6.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from matplotlib) (4.59.2)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from plotly) (2.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: textstat in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (0.7.11)\n",
      "Requirement already satisfied: language-tool-python in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (2.9.5)\n",
      "Requirement already satisfied: pyspellchecker in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (0.8.3)\n",
      "Requirement already satisfied: nltk in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from textstat) (3.9.2)\n",
      "Requirement already satisfied: pyphen in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from textstat) (0.17.2)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from textstat) (59.6.0)\n",
      "Requirement already satisfied: toml in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from language-tool-python) (0.10.2)\n",
      "Requirement already satisfied: requests in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from language-tool-python) (2.32.5)\n",
      "Requirement already satisfied: tqdm in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from language-tool-python) (4.67.1)\n",
      "Requirement already satisfied: psutil in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from language-tool-python) (7.1.1)\n",
      "Requirement already satisfied: joblib in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from nltk->textstat) (1.5.2)\n",
      "Requirement already satisfied: click in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from nltk->textstat) (8.2.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from nltk->textstat) (2025.9.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from requests->language-tool-python) (2025.10.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->language-tool-python) (3.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from requests->language-tool-python) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from requests->language-tool-python) (2.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sqlalchemy in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (2.0.43)\n",
      "Requirement already satisfied: pydantic in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (2.12.4)\n",
      "Requirement already satisfied: fastapi in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (0.117.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from sqlalchemy) (4.15.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from sqlalchemy) (3.2.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from pydantic) (0.4.2)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from pydantic) (2.41.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from fastapi) (0.48.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from starlette<0.49.0,>=0.40.0->fastapi) (4.10.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi) (3.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/os-sunnie.gd.weng/.local/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# å®‰è£æ ¸å¿ƒä¾è³´å¥—ä»¶\n",
    "!pip install scikit-learn pandas numpy matplotlib seaborn plotly\n",
    "!pip install textstat language-tool-python pyspellchecker\n",
    "!pip install sqlalchemy pydantic fastapi\n",
    "!pip install schedule APScheduler\n",
    "!pip install anomaly-detection-toolkit pyod\n",
    "\n",
    "# æ©Ÿå™¨å­¸ç¿’èˆ‡çµ±è¨ˆ\n",
    "!pip install scipy statsmodels\n",
    "\n",
    "# æ™‚é–“åºåˆ—åˆ†æ\n",
    "!pip install prophet fbprophet --quiet || echo \"Prophet installation failed, continuing...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ç’°å¢ƒè¨­å®šå®Œæˆ\n",
      "ğŸ“‚ å°ˆæ¡ˆæ ¹ç›®éŒ„: /home/os-sunnie.gd.weng/python_workstation/side-project/RAG/data_governance/kms_governance\n"
     ]
    }
   ],
   "source": [
    "# å°å…¥å¿…è¦çš„å‡½å¼åº«\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import sqlite3\n",
    "import logging\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from typing import List, Dict, Optional, Tuple, Any, Union\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from enum import Enum\n",
    "from collections import defaultdict, deque\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è³‡æ–™è™•ç†èˆ‡åˆ†æ\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# æ–‡æœ¬å“è³ªåˆ†æ\n",
    "import textstat\n",
    "import language_tool_python\n",
    "from spellchecker import SpellChecker\n",
    "import re\n",
    "\n",
    "# è³‡æ–™åº«èˆ‡è³‡æ–™æ¨¡å‹\n",
    "from sqlalchemy import create_engine, Column, String, Integer, Float, DateTime, Text, JSON, Boolean\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "# å¯è¦–åŒ–\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# ä»»å‹™èª¿åº¦\n",
    "import schedule\n",
    "import time\n",
    "import threading\n",
    "\n",
    "# è¨­å®šå°ˆæ¡ˆè·¯å¾‘\n",
    "PROJECT_ROOT = Path('/home/os-sunnie.gd.weng/python_workstation/side-project/RAG/data_governance/kms_governance')\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "# é…ç½®æ—¥èªŒ\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(PROJECT_ROOT / 'quality_control.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger('QualityControl')\n",
    "\n",
    "print(\"âœ… ç’°å¢ƒè¨­å®šå®Œæˆ\")\n",
    "print(f\"ğŸ“‚ å°ˆæ¡ˆæ ¹ç›®éŒ„: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ å“è³ªæ§åˆ¶è³‡æ–™æ¨¡å‹\n",
    "\n",
    "### å“è³ªæŒ‡æ¨™å®šç¾©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å“è³ªæ§åˆ¶è³‡æ–™æ¨¡å‹å®šç¾©å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# SQLAlchemy åŸºç¤è¨­å®š\n",
    "Base = declarative_base()\n",
    "\n",
    "class QualityDimension(Enum):\n",
    "    \"\"\"å“è³ªç¶­åº¦æšèˆ‰\"\"\"\n",
    "    ACCURACY = \"accuracy\"\n",
    "    COMPLETENESS = \"completeness\"\n",
    "    CONSISTENCY = \"consistency\"\n",
    "    CURRENCY = \"currency\"\n",
    "    UNDERSTANDABILITY = \"understandability\"\n",
    "    TRACEABILITY = \"traceability\"\n",
    "\n",
    "class QualityStatus(Enum):\n",
    "    \"\"\"å“è³ªç‹€æ…‹æšèˆ‰\"\"\"\n",
    "    EXCELLENT = \"excellent\"  # > 0.9\n",
    "    GOOD = \"good\"           # 0.7 - 0.9\n",
    "    FAIR = \"fair\"           # 0.5 - 0.7\n",
    "    POOR = \"poor\"           # < 0.5\n",
    "\n",
    "class AlertSeverity(Enum):\n",
    "    \"\"\"è­¦å ±åš´é‡ç¨‹åº¦\"\"\"\n",
    "    LOW = \"low\"\n",
    "    MEDIUM = \"medium\"\n",
    "    HIGH = \"high\"\n",
    "    CRITICAL = \"critical\"\n",
    "\n",
    "@dataclass\n",
    "class QualityMetrics:\n",
    "    \"\"\"å“è³ªæŒ‡æ¨™è³‡æ–™é¡åˆ¥\"\"\"\n",
    "    accuracy: float = 0.0\n",
    "    completeness: float = 0.0\n",
    "    consistency: float = 0.0\n",
    "    currency: float = 0.0\n",
    "    understandability: float = 0.0\n",
    "    traceability: float = 0.0\n",
    "    overall_score: float = 0.0\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, float]:\n",
    "        return asdict(self)\n",
    "    \n",
    "    def get_status(self) -> QualityStatus:\n",
    "        \"\"\"æ ¹æ“šç¶œåˆåˆ†æ•¸åˆ¤æ–·å“è³ªç‹€æ…‹\"\"\"\n",
    "        if self.overall_score > 0.9:\n",
    "            return QualityStatus.EXCELLENT\n",
    "        elif self.overall_score > 0.7:\n",
    "            return QualityStatus.GOOD\n",
    "        elif self.overall_score > 0.5:\n",
    "            return QualityStatus.FAIR\n",
    "        else:\n",
    "            return QualityStatus.POOR\n",
    "\n",
    "@dataclass\n",
    "class QualityRule:\n",
    "    \"\"\"å“è³ªè¦å‰‡å®šç¾©\"\"\"\n",
    "    rule_id: str\n",
    "    name: str\n",
    "    description: str\n",
    "    dimension: QualityDimension\n",
    "    threshold: float\n",
    "    weight: float = 1.0\n",
    "    active: bool = True\n",
    "\n",
    "# å“è³ªè©•ä¼°è¨˜éŒ„è¡¨\n",
    "class QualityAssessment(Base):\n",
    "    \"\"\"å“è³ªè©•ä¼°è¨˜éŒ„è¡¨\"\"\"\n",
    "    __tablename__ = 'quality_assessments'\n",
    "    \n",
    "    assessment_id = Column(String(50), primary_key=True)\n",
    "    document_id = Column(String(50), nullable=False, index=True)\n",
    "    chunk_id = Column(String(50), index=True)  # å¯é¸ï¼Œé‡å°åˆ†å¡Šçš„è©•ä¼°\n",
    "    \n",
    "    # å“è³ªæŒ‡æ¨™åˆ†æ•¸\n",
    "    accuracy_score = Column(Float, nullable=False)\n",
    "    completeness_score = Column(Float, nullable=False)\n",
    "    consistency_score = Column(Float, nullable=False)\n",
    "    currency_score = Column(Float, nullable=False)\n",
    "    understandability_score = Column(Float, nullable=False)\n",
    "    traceability_score = Column(Float, nullable=False)\n",
    "    overall_score = Column(Float, nullable=False, index=True)\n",
    "    \n",
    "    # è©³ç´°è³‡è¨Š\n",
    "    quality_status = Column(String(20), nullable=False, index=True)\n",
    "    assessment_details = Column(JSON)  # è©³ç´°çš„è©•ä¼°çµæœ\n",
    "    \n",
    "    # è©•ä¼°é…ç½®\n",
    "    assessor_version = Column(String(20), default='1.0')\n",
    "    rules_applied = Column(JSON)  # æ‡‰ç”¨çš„å“è³ªè¦å‰‡\n",
    "    \n",
    "    # æ™‚é–“è³‡è¨Š\n",
    "    assessed_at = Column(DateTime, default=datetime.now, index=True)\n",
    "    processing_time_ms = Column(Integer)\n",
    "    \n",
    "    # å‚™è¨»\n",
    "    notes = Column(Text)\n",
    "\n",
    "# å“è³ªç•°å¸¸è¨˜éŒ„è¡¨\n",
    "class QualityAnomaly(Base):\n",
    "    \"\"\"å“è³ªç•°å¸¸è¨˜éŒ„è¡¨\"\"\"\n",
    "    __tablename__ = 'quality_anomalies'\n",
    "    \n",
    "    anomaly_id = Column(String(50), primary_key=True)\n",
    "    document_id = Column(String(50), nullable=False, index=True)\n",
    "    assessment_id = Column(String(50), nullable=False)\n",
    "    \n",
    "    # ç•°å¸¸è³‡è¨Š\n",
    "    anomaly_type = Column(String(50), nullable=False)  # score_drop, threshold_breach, etc.\n",
    "    affected_dimension = Column(String(50), nullable=False)\n",
    "    anomaly_score = Column(Float, nullable=False)  # ç•°å¸¸ç¨‹åº¦åˆ†æ•¸\n",
    "    \n",
    "    # é–¾å€¼è³‡è¨Š\n",
    "    expected_value = Column(Float)\n",
    "    actual_value = Column(Float)\n",
    "    threshold_value = Column(Float)\n",
    "    \n",
    "    # æª¢æ¸¬æ–¹æ³•\n",
    "    detection_method = Column(String(50), nullable=False)\n",
    "    detector_config = Column(JSON)\n",
    "    \n",
    "    # ç‹€æ…‹ç®¡ç†\n",
    "    status = Column(String(20), default='open')  # open, investigating, resolved, false_positive\n",
    "    severity = Column(String(20), nullable=False)\n",
    "    \n",
    "    # æ™‚é–“è³‡è¨Š\n",
    "    detected_at = Column(DateTime, default=datetime.now, index=True)\n",
    "    resolved_at = Column(DateTime)\n",
    "    \n",
    "    # è™•ç†è³‡è¨Š\n",
    "    assigned_to = Column(String(100))\n",
    "    resolution_notes = Column(Text)\n",
    "\n",
    "# å“è³ªè¶¨å‹¢è¡¨\n",
    "class QualityTrend(Base):\n",
    "    \"\"\"å“è³ªè¶¨å‹¢åˆ†æè¡¨\"\"\"\n",
    "    __tablename__ = 'quality_trends'\n",
    "    \n",
    "    trend_id = Column(String(50), primary_key=True)\n",
    "    \n",
    "    # æ™‚é–“çª—å£\n",
    "    period_start = Column(DateTime, nullable=False, index=True)\n",
    "    period_end = Column(DateTime, nullable=False)\n",
    "    period_type = Column(String(20), nullable=False)  # daily, weekly, monthly\n",
    "    \n",
    "    # çµ±è¨ˆè³‡è¨Š\n",
    "    document_count = Column(Integer, nullable=False)\n",
    "    avg_overall_score = Column(Float, nullable=False)\n",
    "    min_score = Column(Float, nullable=False)\n",
    "    max_score = Column(Float, nullable=False)\n",
    "    std_score = Column(Float, nullable=False)\n",
    "    \n",
    "    # åˆ†ç¶­åº¦çµ±è¨ˆ\n",
    "    dimension_averages = Column(JSON, nullable=False)\n",
    "    \n",
    "    # åˆ†ä½ˆçµ±è¨ˆ\n",
    "    status_distribution = Column(JSON)  # excellent, good, fair, poor çš„åˆ†ä½ˆ\n",
    "    type_distribution = Column(JSON)    # ä¸åŒæ–‡æª”é¡å‹çš„å“è³ªåˆ†ä½ˆ\n",
    "    \n",
    "    # ç•°å¸¸çµ±è¨ˆ\n",
    "    anomaly_count = Column(Integer, default=0)\n",
    "    critical_anomaly_count = Column(Integer, default=0)\n",
    "    \n",
    "    # è¨ˆç®—æ™‚é–“\n",
    "    calculated_at = Column(DateTime, default=datetime.now)\n",
    "\n",
    "print(\"âœ… å“è³ªæ§åˆ¶è³‡æ–™æ¨¡å‹å®šç¾©å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pydantic é©—è­‰æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Pydantic é©—è­‰æ¨¡å‹å®šç¾©å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# Pydantic æ¨¡å‹ç”¨æ–¼ API å’Œè³‡æ–™é©—è­‰\n",
    "\n",
    "class QualityAssessmentRequest(BaseModel):\n",
    "    \"\"\"å“è³ªè©•ä¼°è«‹æ±‚æ¨¡å‹\"\"\"\n",
    "    document_id: str = Field(..., min_length=1)\n",
    "    chunk_id: Optional[str] = None\n",
    "    content: str = Field(..., min_length=1)\n",
    "    force_reassessment: bool = Field(default=False)\n",
    "    custom_rules: Optional[List[Dict]] = None\n",
    "    \n",
    "    @validator('content')\n",
    "    def validate_content_length(cls, v):\n",
    "        if len(v.strip()) < 10:\n",
    "            raise ValueError('Content too short for quality assessment')\n",
    "        return v\n",
    "\n",
    "class QualityThreshold(BaseModel):\n",
    "    \"\"\"å“è³ªé–¾å€¼è¨­å®šæ¨¡å‹\"\"\"\n",
    "    dimension: str = Field(..., pattern=\"^(accuracy|completeness|consistency|currency|understandability|traceability|overall)$\")\n",
    "    min_acceptable: float = Field(..., ge=0.0, le=1.0)\n",
    "    target_value: float = Field(..., ge=0.0, le=1.0)\n",
    "    weight: float = Field(default=1.0, ge=0.0, le=10.0)\n",
    "    \n",
    "    @validator('target_value')\n",
    "    def target_must_be_higher_than_min(cls, v, values):\n",
    "        if 'min_acceptable' in values and v < values['min_acceptable']:\n",
    "            raise ValueError('Target value must be >= min_acceptable')\n",
    "        return v\n",
    "\n",
    "class AnomalyDetectionConfig(BaseModel):\n",
    "    \"\"\"ç•°å¸¸æª¢æ¸¬é…ç½®æ¨¡å‹\"\"\"\n",
    "    method: str = Field(..., pattern=\"^(statistical|isolation_forest|one_class_svm|zscore)$\")\n",
    "    sensitivity: float = Field(default=0.1, ge=0.01, le=0.5)\n",
    "    min_samples: int = Field(default=10, ge=5)\n",
    "    lookback_days: int = Field(default=30, ge=1, le=365)\n",
    "    enable_multivariate: bool = Field(default=True)\n",
    "\n",
    "class QualityReport(BaseModel):\n",
    "    \"\"\"å“è³ªå ±å‘Šæ¨¡å‹\"\"\"\n",
    "    report_id: str\n",
    "    period_start: datetime\n",
    "    period_end: datetime\n",
    "    summary: Dict[str, Any]\n",
    "    trends: List[Dict[str, Any]]\n",
    "    anomalies: List[Dict[str, Any]]\n",
    "    recommendations: List[str]\n",
    "    generated_at: datetime\n",
    "\n",
    "print(\"âœ… Pydantic é©—è­‰æ¨¡å‹å®šç¾©å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” å¤šç¶­åº¦å“è³ªè©•ä¼°å¼•æ“\n",
    "\n",
    "### æ ¸å¿ƒè©•ä¼°å™¨å¯¦ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… MultiDimensionalQualityAssessor æ ¸å¿ƒæ–¹æ³•å®šç¾©å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "class MultiDimensionalQualityAssessor:\n",
    "    \"\"\"\n",
    "    å¤šç¶­åº¦å“è³ªè©•ä¼°å¼•æ“\n",
    "    åŸºæ–¼ ISO 25012 æ¨™æº–å¯¦ä½œå…¨é¢çš„å“è³ªè©•ä¼°\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, language: str = 'en'):\n",
    "        \"\"\"åˆå§‹åŒ–å“è³ªè©•ä¼°å™¨\"\"\"\n",
    "        self.language = language\n",
    "        self.version = \"1.0\"\n",
    "        \n",
    "        # åˆå§‹åŒ–èªè¨€å·¥å…·\n",
    "        try:\n",
    "            self.grammar_tool = language_tool_python.LanguageTool(language)\n",
    "            print(\"âœ… LanguageTool åˆå§‹åŒ–å®Œæˆ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸  LanguageTool åˆå§‹åŒ–å¤±æ•—: {e}\")\n",
    "            self.grammar_tool = None\n",
    "        \n",
    "        # åˆå§‹åŒ–æ‹¼å­—æª¢æŸ¥å™¨\n",
    "        try:\n",
    "            self.spell_checker = SpellChecker(language=language)\n",
    "            print(\"âœ… SpellChecker åˆå§‹åŒ–å®Œæˆ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸  SpellChecker åˆå§‹åŒ–å¤±æ•—: {e}\")\n",
    "            self.spell_checker = None\n",
    "        \n",
    "        # é è¨­å“è³ªæ¬Šé‡ (åŸºæ–¼ ISO 25012)\n",
    "        self.default_weights = {\n",
    "            'accuracy': 0.20,\n",
    "            'completeness': 0.20,\n",
    "            'consistency': 0.15,\n",
    "            'currency': 0.15,\n",
    "            'understandability': 0.15,\n",
    "            'traceability': 0.15\n",
    "        }\n",
    "        \n",
    "        # å“è³ªé–¾å€¼\n",
    "        self.thresholds = {\n",
    "            'min_word_count': 10,\n",
    "            'max_sentence_length': 40,\n",
    "            'min_readability_score': 30,\n",
    "            'max_spelling_error_rate': 0.05,\n",
    "            'max_grammar_error_rate': 0.03\n",
    "        }\n",
    "        \n",
    "        print(\"âœ… å¤šç¶­åº¦å“è³ªè©•ä¼°å™¨åˆå§‹åŒ–å®Œæˆ\")\n",
    "    \n",
    "    def assess_document_quality(self, \n",
    "                              content: str, \n",
    "                              metadata: Optional[Dict] = None,\n",
    "                              custom_weights: Optional[Dict] = None) -> QualityMetrics:\n",
    "        \"\"\"\n",
    "        è©•ä¼°æ–‡æª”çš„å¤šç¶­åº¦å“è³ª\n",
    "        \n",
    "        Args:\n",
    "            content: æ–‡æª”å…§å®¹\n",
    "            metadata: æ–‡æª”å…ƒè³‡æ–™\n",
    "            custom_weights: è‡ªè¨‚æ¬Šé‡\n",
    "            \n",
    "        Returns:\n",
    "            QualityMetrics: å“è³ªè©•ä¼°çµæœ\n",
    "        \"\"\"\n",
    "        if not content or not content.strip():\n",
    "            return QualityMetrics()\n",
    "        \n",
    "        metadata = metadata or {}\n",
    "        weights = custom_weights or self.default_weights\n",
    "        \n",
    "        try:\n",
    "            # 1. æº–ç¢ºæ€§è©•ä¼°\n",
    "            accuracy = self._assess_accuracy(content)\n",
    "            \n",
    "            # 2. å®Œæ•´æ€§è©•ä¼°\n",
    "            completeness = self._assess_completeness(content, metadata)\n",
    "            \n",
    "            # 3. ä¸€è‡´æ€§è©•ä¼°\n",
    "            consistency = self._assess_consistency(content)\n",
    "            \n",
    "            # 4. æ™‚æ•ˆæ€§è©•ä¼°\n",
    "            currency = self._assess_currency(content, metadata)\n",
    "            \n",
    "            # 5. å¯ç†è§£æ€§è©•ä¼°\n",
    "            understandability = self._assess_understandability(content)\n",
    "            \n",
    "            # 6. å¯è¿½æº¯æ€§è©•ä¼°\n",
    "            traceability = self._assess_traceability(content, metadata)\n",
    "            \n",
    "            # è¨ˆç®—ç¶œåˆå“è³ªåˆ†æ•¸\n",
    "            overall_score = (\n",
    "                weights['accuracy'] * accuracy +\n",
    "                weights['completeness'] * completeness +\n",
    "                weights['consistency'] * consistency +\n",
    "                weights['currency'] * currency +\n",
    "                weights['understandability'] * understandability +\n",
    "                weights['traceability'] * traceability\n",
    "            )\n",
    "            \n",
    "            return QualityMetrics(\n",
    "                accuracy=accuracy,\n",
    "                completeness=completeness,\n",
    "                consistency=consistency,\n",
    "                currency=currency,\n",
    "                understandability=understandability,\n",
    "                traceability=traceability,\n",
    "                overall_score=overall_score\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"å“è³ªè©•ä¼°å¤±æ•—: {e}\")\n",
    "            return QualityMetrics()\n",
    "    \n",
    "    def _assess_accuracy(self, content: str) -> float:\n",
    "        \"\"\"\n",
    "        è©•ä¼°æº–ç¢ºæ€§\n",
    "        åŸºæ–¼èªæ³•éŒ¯èª¤ã€æ‹¼å­—éŒ¯èª¤ã€æ ¼å¼ä¸€è‡´æ€§\n",
    "        \"\"\"\n",
    "        accuracy_score = 1.0\n",
    "        \n",
    "        # æ‹¼å­—éŒ¯èª¤æª¢æŸ¥\n",
    "        if self.spell_checker:\n",
    "            words = re.findall(r'\\b\\w+\\b', content.lower())\n",
    "            if words:\n",
    "                misspelled = self.spell_checker.unknown(words)\n",
    "                spelling_error_rate = len(misspelled) / len(words)\n",
    "                spelling_penalty = min(spelling_error_rate / self.thresholds['max_spelling_error_rate'], 1.0)\n",
    "                accuracy_score -= 0.3 * spelling_penalty\n",
    "        \n",
    "        # èªæ³•éŒ¯èª¤æª¢æŸ¥\n",
    "        if self.grammar_tool:\n",
    "            try:\n",
    "                # é™åˆ¶æª¢æŸ¥é•·åº¦é¿å…è¶…æ™‚\n",
    "                check_content = content[:2000] if len(content) > 2000 else content\n",
    "                grammar_errors = self.grammar_tool.check(check_content)\n",
    "                words_count = len(check_content.split())\n",
    "                \n",
    "                if words_count > 0:\n",
    "                    grammar_error_rate = len(grammar_errors) / words_count\n",
    "                    grammar_penalty = min(grammar_error_rate / self.thresholds['max_grammar_error_rate'], 1.0)\n",
    "                    accuracy_score -= 0.4 * grammar_penalty\n",
    "            except Exception:\n",
    "                pass  # å¿½ç•¥èªæ³•æª¢æŸ¥éŒ¯èª¤\n",
    "        \n",
    "        # æ ¼å¼ä¸€è‡´æ€§æª¢æŸ¥\n",
    "        format_consistency = self._check_format_consistency(content)\n",
    "        accuracy_score -= 0.3 * (1.0 - format_consistency)\n",
    "        \n",
    "        return max(0.0, min(1.0, accuracy_score))\n",
    "    \n",
    "    def _assess_completeness(self, content: str, metadata: Dict) -> float:\n",
    "        \"\"\"\n",
    "        è©•ä¼°å®Œæ•´æ€§\n",
    "        åŸºæ–¼å…§å®¹é•·åº¦ã€çµæ§‹å®Œæ•´æ€§ã€å¿…è¦å…ƒç´ å­˜åœ¨\n",
    "        \"\"\"\n",
    "        completeness_score = 0.0\n",
    "        \n",
    "        # 1. å…§å®¹é•·åº¦è©•ä¼° (40%)\n",
    "        word_count = len(content.split())\n",
    "        if word_count >= self.thresholds['min_word_count']:\n",
    "            # åŸºæ–¼å°æ•¸å‡½æ•¸çš„è©•åˆ†ï¼Œé¿å…éåº¦æ‡²ç½°é•·æ–‡æª”\n",
    "            length_score = min(1.0, np.log10(word_count) / 3.0)\n",
    "            completeness_score += 0.4 * length_score\n",
    "        \n",
    "        # 2. çµæ§‹å®Œæ•´æ€§è©•ä¼° (30%)\n",
    "        structure_score = self._assess_document_structure(content)\n",
    "        completeness_score += 0.3 * structure_score\n",
    "        \n",
    "        # 3. å…ƒè³‡æ–™å®Œæ•´æ€§è©•ä¼° (20%)\n",
    "        metadata_score = self._assess_metadata_completeness(metadata)\n",
    "        completeness_score += 0.2 * metadata_score\n",
    "        \n",
    "        # 4. å…§å®¹è¦†è“‹åº¦è©•ä¼° (10%)\n",
    "        coverage_score = self._assess_content_coverage(content)\n",
    "        completeness_score += 0.1 * coverage_score\n",
    "        \n",
    "        return max(0.0, min(1.0, completeness_score))\n",
    "    \n",
    "    def _assess_consistency(self, content: str) -> float:\n",
    "        \"\"\"\n",
    "        è©•ä¼°ä¸€è‡´æ€§\n",
    "        åŸºæ–¼è¡“èªä½¿ç”¨ã€æ ¼å¼é¢¨æ ¼ã€å¯«ä½œé¢¨æ ¼çš„ä¸€è‡´æ€§\n",
    "        \"\"\"\n",
    "        consistency_score = 1.0\n",
    "        \n",
    "        # 1. è¡“èªä¸€è‡´æ€§æª¢æŸ¥\n",
    "        terminology_consistency = self._check_terminology_consistency(content)\n",
    "        consistency_score *= terminology_consistency\n",
    "        \n",
    "        # 2. æ ¼å¼ä¸€è‡´æ€§æª¢æŸ¥\n",
    "        format_consistency = self._check_format_consistency(content)\n",
    "        consistency_score *= format_consistency\n",
    "        \n",
    "        # 3. å¯«ä½œé¢¨æ ¼ä¸€è‡´æ€§\n",
    "        style_consistency = self._check_writing_style_consistency(content)\n",
    "        consistency_score *= style_consistency\n",
    "        \n",
    "        return max(0.0, min(1.0, consistency_score))\n",
    "    \n",
    "    def _assess_currency(self, content: str, metadata: Dict) -> float:\n",
    "        \"\"\"\n",
    "        è©•ä¼°æ™‚æ•ˆæ€§\n",
    "        åŸºæ–¼æ–‡æª”å¹´é½¡ã€å…§å®¹æ–°é®®åº¦ã€å¼•ç”¨æ–°ç©æ€§\n",
    "        \"\"\"\n",
    "        currency_score = 1.0\n",
    "        \n",
    "        # 1. æ–‡æª”å¹´é½¡è©•ä¼°\n",
    "        if 'created_date' in metadata:\n",
    "            try:\n",
    "                created_date = metadata['created_date']\n",
    "                if isinstance(created_date, str):\n",
    "                    created_date = datetime.fromisoformat(created_date.replace('Z', '+00:00'))\n",
    "                \n",
    "                age_days = (datetime.now() - created_date).days\n",
    "                \n",
    "                # åŸºæ–¼æ–‡æª”é¡å‹èª¿æ•´è¡°æ¸›ç‡\n",
    "                doc_type = metadata.get('document_type', 'unknown')\n",
    "                if doc_type == 'academic_paper':\n",
    "                    half_life_days = 1825  # å­¸è¡“è«–æ–‡5å¹´åŠè¡°æœŸ\n",
    "                elif doc_type == 'business_report':\n",
    "                    half_life_days = 365   # å•†æ¥­å ±å‘Š1å¹´åŠè¡°æœŸ\n",
    "                else:\n",
    "                    half_life_days = 730   # é è¨­2å¹´åŠè¡°æœŸ\n",
    "                \n",
    "                # ä½¿ç”¨æŒ‡æ•¸è¡°æ¸›æ¨¡å‹\n",
    "                age_factor = np.exp(-0.693 * age_days / half_life_days)\n",
    "                currency_score *= age_factor\n",
    "                \n",
    "            except Exception:\n",
    "                currency_score *= 0.5  # ç„¡æ³•ç¢ºå®šå¹´é½¡æ™‚çš„æ‡²ç½°\n",
    "        \n",
    "        # 2. å…§å®¹æ–°é®®åº¦è©•ä¼°ï¼ˆæª¢æŸ¥æ˜¯å¦åŒ…å«æœ€æ–°è³‡è¨Šï¼‰\n",
    "        freshness_score = self._assess_content_freshness(content)\n",
    "        currency_score = 0.7 * currency_score + 0.3 * freshness_score\n",
    "        \n",
    "        return max(0.0, min(1.0, currency_score))\n",
    "    \n",
    "    def _assess_understandability(self, content: str) -> float:\n",
    "        \"\"\"\n",
    "        è©•ä¼°å¯ç†è§£æ€§\n",
    "        åŸºæ–¼å¯è®€æ€§æŒ‡æ¨™ã€å¥å­è¤‡é›œåº¦ã€å°ˆæ¥­è¡“èªå¯†åº¦\n",
    "        \"\"\"\n",
    "        understandability_score = 0.0\n",
    "        \n",
    "        try:\n",
    "            # 1. Flesch Reading Ease Score (40%)\n",
    "            flesch_score = textstat.flesch_reading_ease(content)\n",
    "            # å°‡ Flesch åˆ†æ•¸ (0-100) æ­£è¦åŒ–ç‚º 0-1\n",
    "            normalized_flesch = max(0, min(100, flesch_score)) / 100\n",
    "            understandability_score += 0.4 * normalized_flesch\n",
    "            \n",
    "            # 2. å¹³å‡å¥å­é•·åº¦è©•ä¼° (25%)\n",
    "            avg_sentence_length = textstat.avg_sentence_length(content)\n",
    "            # ç†æƒ³å¥å­é•·åº¦ç‚º15-25å­—ï¼Œè¶…å‡ºç¯„åœæœƒé™ä½åˆ†æ•¸\n",
    "            if 15 <= avg_sentence_length <= 25:\n",
    "                sentence_score = 1.0\n",
    "            else:\n",
    "                deviation = min(abs(avg_sentence_length - 20), 20)\n",
    "                sentence_score = max(0, 1.0 - deviation / 20)\n",
    "            understandability_score += 0.25 * sentence_score\n",
    "            \n",
    "            # 3. è©å½™è¤‡é›œåº¦è©•ä¼° (20%)\n",
    "            difficult_words_ratio = textstat.difficult_words(content) / max(1, textstat.lexicon_count(content))\n",
    "            vocabulary_score = max(0, 1.0 - difficult_words_ratio)\n",
    "            understandability_score += 0.2 * vocabulary_score\n",
    "            \n",
    "            # 4. æ®µè½çµæ§‹è©•ä¼° (15%)\n",
    "            paragraph_score = self._assess_paragraph_structure(content)\n",
    "            understandability_score += 0.15 * paragraph_score\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"å¯ç†è§£æ€§è©•ä¼°éƒ¨åˆ†å¤±æ•—: {e}\")\n",
    "            understandability_score = 0.5  # é è¨­ä¸­ç­‰åˆ†æ•¸\n",
    "        \n",
    "        return max(0.0, min(1.0, understandability_score))\n",
    "    \n",
    "    def _assess_traceability(self, content: str, metadata: Dict) -> float:\n",
    "        \"\"\"\n",
    "        è©•ä¼°å¯è¿½æº¯æ€§\n",
    "        åŸºæ–¼ä¾†æºæ¨™è¨»ã€å¼•ç”¨å®Œæ•´æ€§ã€ç‰ˆæœ¬è³‡è¨Š\n",
    "        \"\"\"\n",
    "        traceability_score = 0.0\n",
    "        \n",
    "        # 1. å…ƒè³‡æ–™è¿½æº¯æ€§ (40%)\n",
    "        metadata_trace_score = 0.0\n",
    "        required_metadata = ['authors', 'created_date', 'source_url', 'version']\n",
    "        \n",
    "        for field in required_metadata:\n",
    "            if field in metadata and metadata[field]:\n",
    "                metadata_trace_score += 0.25\n",
    "        \n",
    "        traceability_score += 0.4 * metadata_trace_score\n",
    "        \n",
    "        # 2. å¼•ç”¨å’Œåƒè€ƒæ–‡ç» (35%)\n",
    "        citation_score = self._assess_citations(content)\n",
    "        traceability_score += 0.35 * citation_score\n",
    "        \n",
    "        # 3. ä¾†æºæ¨™ç¤º (25%)\n",
    "        source_attribution_score = self._assess_source_attribution(content)\n",
    "        traceability_score += 0.25 * source_attribution_score\n",
    "        \n",
    "        return max(0.0, min(1.0, traceability_score))\n",
    "\n",
    "print(\"âœ… MultiDimensionalQualityAssessor æ ¸å¿ƒæ–¹æ³•å®šç¾©å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è¼”åŠ©è©•ä¼°æ–¹æ³•å¯¦ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… MultiDimensionalQualityAssessor è¼”åŠ©æ–¹æ³•å®šç¾©å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# ç¹¼çºŒ MultiDimensionalQualityAssessor çš„è¼”åŠ©æ–¹æ³•\n",
    "\n",
    "def _check_format_consistency(self, content: str) -> float:\n",
    "    \"\"\"æª¢æŸ¥æ ¼å¼ä¸€è‡´æ€§\"\"\"\n",
    "    consistency_score = 1.0\n",
    "    \n",
    "    # æª¢æŸ¥æ¨™é¡Œæ ¼å¼ä¸€è‡´æ€§\n",
    "    title_patterns = [\n",
    "        r'^\\d+\\.\\s+\\w+',  # \"1. Title\"\n",
    "        r'^#+\\s+\\w+',      # \"# Title\" or \"## Title\"\n",
    "        r'^[A-Z][^\\n]*:$', # \"Title:\"\n",
    "    ]\n",
    "    \n",
    "    title_matches = []\n",
    "    for pattern in title_patterns:\n",
    "        matches = re.findall(pattern, content, re.MULTILINE)\n",
    "        if matches:\n",
    "            title_matches.append(len(matches))\n",
    "    \n",
    "    # å¦‚æœæœ‰å¤šç¨®æ¨™é¡Œæ ¼å¼ï¼Œé™ä½ä¸€è‡´æ€§åˆ†æ•¸\n",
    "    if len(title_matches) > 1:\n",
    "        consistency_score *= 0.8\n",
    "    \n",
    "    # æª¢æŸ¥åˆ—è¡¨æ ¼å¼ä¸€è‡´æ€§\n",
    "    list_patterns = [\n",
    "        r'^\\s*[-*+]\\s+',   # bullet points\n",
    "        r'^\\s*\\d+\\.\\s+',   # numbered lists\n",
    "        r'^\\s*[a-z]\\)\\s+', # lettered lists\n",
    "    ]\n",
    "    \n",
    "    list_format_count = 0\n",
    "    for pattern in list_patterns:\n",
    "        if re.search(pattern, content, re.MULTILINE):\n",
    "            list_format_count += 1\n",
    "    \n",
    "    if list_format_count > 1:\n",
    "        consistency_score *= 0.9\n",
    "    \n",
    "    return consistency_score\n",
    "\n",
    "def _check_terminology_consistency(self, content: str) -> float:\n",
    "    \"\"\"æª¢æŸ¥è¡“èªä¸€è‡´æ€§\"\"\"\n",
    "    # ç°¡åŒ–å¯¦ä½œï¼šæª¢æŸ¥åŒç¾©è©çš„ä½¿ç”¨ä¸€è‡´æ€§\n",
    "    synonyms_groups = [\n",
    "        ['AI', 'artificial intelligence', 'machine intelligence'],\n",
    "        ['ML', 'machine learning'],\n",
    "        ['DL', 'deep learning'],\n",
    "        ['NLP', 'natural language processing'],\n",
    "        ['API', 'application programming interface']\n",
    "    ]\n",
    "    \n",
    "    consistency_penalty = 0.0\n",
    "    \n",
    "    for group in synonyms_groups:\n",
    "        found_variants = []\n",
    "        for term in group:\n",
    "            if re.search(r'\\b' + re.escape(term) + r'\\b', content, re.IGNORECASE):\n",
    "                found_variants.append(term)\n",
    "        \n",
    "        # å¦‚æœä½¿ç”¨äº†å¤šç¨®åŒç¾©è©ï¼Œæ‰£åˆ†\n",
    "        if len(found_variants) > 1:\n",
    "            consistency_penalty += 0.05\n",
    "    \n",
    "    return max(0.0, 1.0 - consistency_penalty)\n",
    "\n",
    "def _check_writing_style_consistency(self, content: str) -> float:\n",
    "    \"\"\"æª¢æŸ¥å¯«ä½œé¢¨æ ¼ä¸€è‡´æ€§\"\"\"\n",
    "    sentences = re.split(r'[.!?]+', content)\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "    \n",
    "    if len(sentences) < 3:\n",
    "        return 1.0  # å¤ªçŸ­ç„¡æ³•è©•ä¼°\n",
    "    \n",
    "    # æª¢æŸ¥å¥å­é•·åº¦è®Šç•°æ€§\n",
    "    sentence_lengths = [len(s.split()) for s in sentences]\n",
    "    length_cv = np.std(sentence_lengths) / (np.mean(sentence_lengths) + 1e-6)\n",
    "    \n",
    "    # è®Šç•°ä¿‚æ•¸è¶Šå¤§ï¼Œä¸€è‡´æ€§è¶Šä½\n",
    "    length_consistency = max(0.0, 1.0 - min(length_cv / 1.5, 1.0))\n",
    "    \n",
    "    return length_consistency\n",
    "\n",
    "def _assess_document_structure(self, content: str) -> float:\n",
    "    \"\"\"è©•ä¼°æ–‡æª”çµæ§‹å®Œæ•´æ€§\"\"\"\n",
    "    structure_score = 0.0\n",
    "    \n",
    "    # æª¢æŸ¥æ˜¯å¦æœ‰æ¨™é¡Œ\n",
    "    title_patterns = [r'^.{1,100}$', r'^#+\\s+.+$', r'^\\d+\\.\\s+.+$']\n",
    "    has_titles = any(re.search(pattern, content, re.MULTILINE) for pattern in title_patterns)\n",
    "    if has_titles:\n",
    "        structure_score += 0.3\n",
    "    \n",
    "    # æª¢æŸ¥æ˜¯å¦æœ‰æ®µè½åˆ†éš”\n",
    "    paragraphs = content.split('\\n\\n')\n",
    "    if len(paragraphs) > 1:\n",
    "        structure_score += 0.2\n",
    "    \n",
    "    # æª¢æŸ¥æ˜¯å¦æœ‰åˆ—è¡¨æˆ–è¦é»\n",
    "    list_pattern = r'^\\s*[-*+\\d]+[\\.)\\s]'\n",
    "    if re.search(list_pattern, content, re.MULTILINE):\n",
    "        structure_score += 0.2\n",
    "    \n",
    "    # æª¢æŸ¥æ®µè½é•·åº¦åˆç†æ€§\n",
    "    avg_paragraph_length = np.mean([len(p.split()) for p in paragraphs if p.strip()])\n",
    "    if 20 <= avg_paragraph_length <= 200:\n",
    "        structure_score += 0.3\n",
    "    \n",
    "    return min(1.0, structure_score)\n",
    "\n",
    "def _assess_metadata_completeness(self, metadata: Dict) -> float:\n",
    "    \"\"\"è©•ä¼°å…ƒè³‡æ–™å®Œæ•´æ€§\"\"\"\n",
    "    if not metadata:\n",
    "        return 0.0\n",
    "    \n",
    "    # é‡è¦å…ƒè³‡æ–™æ¬„ä½åŠå…¶æ¬Šé‡\n",
    "    important_fields = {\n",
    "        'title': 0.25,\n",
    "        'authors': 0.20,\n",
    "        'created_date': 0.15,\n",
    "        'document_type': 0.15,\n",
    "        'keywords': 0.10,\n",
    "        'language': 0.05,\n",
    "        'organization': 0.10\n",
    "    }\n",
    "    \n",
    "    completeness_score = 0.0\n",
    "    \n",
    "    for field, weight in important_fields.items():\n",
    "        if field in metadata and metadata[field]:\n",
    "            # æª¢æŸ¥å€¼çš„å“è³ª\n",
    "            value = metadata[field]\n",
    "            if isinstance(value, str) and len(value.strip()) > 0:\n",
    "                completeness_score += weight\n",
    "            elif isinstance(value, list) and len(value) > 0:\n",
    "                completeness_score += weight\n",
    "            elif value is not None:\n",
    "                completeness_score += weight\n",
    "    \n",
    "    return completeness_score\n",
    "\n",
    "def _assess_content_coverage(self, content: str) -> float:\n",
    "    \"\"\"è©•ä¼°å…§å®¹è¦†è“‹åº¦\"\"\"\n",
    "    # æª¢æŸ¥å…§å®¹æ˜¯å¦æ¶µè“‹äº†ä¸»è¦è¦ç´ \n",
    "    coverage_indicators = {\n",
    "        'introduction': [r'\\bintroduction\\b', r'\\boverview\\b', r'\\bbackground\\b'],\n",
    "        'methodology': [r'\\bmethodology\\b', r'\\bmethod\\b', r'\\bapproach\\b'],\n",
    "        'results': [r'\\bresults\\b', r'\\bfindings\\b', r'\\boutcome\\b'],\n",
    "        'conclusion': [r'\\bconclusion\\b', r'\\bsummary\\b', r'\\bdiscussion\\b']\n",
    "    }\n",
    "    \n",
    "    coverage_score = 0.0\n",
    "    content_lower = content.lower()\n",
    "    \n",
    "    for section, patterns in coverage_indicators.items():\n",
    "        if any(re.search(pattern, content_lower) for pattern in patterns):\n",
    "            coverage_score += 0.25\n",
    "    \n",
    "    return coverage_score\n",
    "\n",
    "def _assess_content_freshness(self, content: str) -> float:\n",
    "    \"\"\"è©•ä¼°å…§å®¹æ–°é®®åº¦\"\"\"\n",
    "    # æª¢æŸ¥æ˜¯å¦åŒ…å«æœ€è¿‘å¹´ä»½çš„è³‡è¨Š\n",
    "    current_year = datetime.now().year\n",
    "    year_pattern = r'\\b(20\\d{2})\\b'\n",
    "    years_found = [int(year) for year in re.findall(year_pattern, content)]\n",
    "    \n",
    "    if not years_found:\n",
    "        return 0.5  # æ²’æœ‰å¹´ä»½è³‡è¨Š\n",
    "    \n",
    "    # è¨ˆç®—æœ€æ–°å¹´ä»½çš„æ–°é®®åº¦\n",
    "    latest_year = max(years_found)\n",
    "    age = current_year - latest_year\n",
    "    \n",
    "    # 3å¹´å…§ç‚ºæ–°é®®ï¼Œä¹‹å¾Œç·šæ€§è¡°æ¸›\n",
    "    if age <= 3:\n",
    "        return 1.0\n",
    "    elif age <= 10:\n",
    "        return 1.0 - (age - 3) / 7\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def _assess_paragraph_structure(self, content: str) -> float:\n",
    "    \"\"\"è©•ä¼°æ®µè½çµæ§‹\"\"\"\n",
    "    paragraphs = [p.strip() for p in content.split('\\n\\n') if p.strip()]\n",
    "    \n",
    "    if not paragraphs:\n",
    "        return 0.0\n",
    "    \n",
    "    # è©•ä¼°æ®µè½é•·åº¦åˆ†ä½ˆ\n",
    "    paragraph_lengths = [len(p.split()) for p in paragraphs]\n",
    "    avg_length = np.mean(paragraph_lengths)\n",
    "    \n",
    "    # ç†æƒ³æ®µè½é•·åº¦ç‚º50-150å­—\n",
    "    if 50 <= avg_length <= 150:\n",
    "        length_score = 1.0\n",
    "    else:\n",
    "        deviation = min(abs(avg_length - 100), 100)\n",
    "        length_score = max(0, 1.0 - deviation / 100)\n",
    "    \n",
    "    # è©•ä¼°æ®µè½æ•¸é‡åˆç†æ€§\n",
    "    paragraph_count = len(paragraphs)\n",
    "    total_words = sum(paragraph_lengths)\n",
    "    \n",
    "    if total_words > 0:\n",
    "        avg_words_per_paragraph = total_words / paragraph_count\n",
    "        if 30 <= avg_words_per_paragraph <= 200:\n",
    "            count_score = 1.0\n",
    "        else:\n",
    "            count_score = 0.7\n",
    "    else:\n",
    "        count_score = 0.0\n",
    "    \n",
    "    return 0.6 * length_score + 0.4 * count_score\n",
    "\n",
    "def _assess_citations(self, content: str) -> float:\n",
    "    \"\"\"è©•ä¼°å¼•ç”¨å“è³ª\"\"\"\n",
    "    # æª¢æŸ¥å„ç¨®å¼•ç”¨æ ¼å¼\n",
    "    citation_patterns = [\n",
    "        r'\\[\\d+\\]',                    # [1], [2]\n",
    "        r'\\(\\w+\\s+et\\s+al\\.?,?\\s+\\d{4}\\)', # (Smith et al., 2020)\n",
    "        r'\\(\\w+,?\\s+\\d{4}\\)',          # (Smith, 2020)\n",
    "        r'\\w+\\s+\\(\\d{4}\\)',            # Smith (2020)\n",
    "        r'doi:\\s*10\\.\\d+',            # DOI references\n",
    "        r'https?://[\\w.-]+',          # URL references\n",
    "    ]\n",
    "    \n",
    "    citation_count = 0\n",
    "    for pattern in citation_patterns:\n",
    "        matches = re.findall(pattern, content, re.IGNORECASE)\n",
    "        citation_count += len(matches)\n",
    "    \n",
    "    # æ ¹æ“šæ–‡æª”é•·åº¦èª¿æ•´æœŸæœ›çš„å¼•ç”¨æ•¸é‡\n",
    "    word_count = len(content.split())\n",
    "    expected_citations = max(1, word_count // 500)  # æ¯500å­—æœŸæœ›1å€‹å¼•ç”¨\n",
    "    \n",
    "    citation_ratio = min(citation_count / expected_citations, 1.0)\n",
    "    \n",
    "    return citation_ratio\n",
    "\n",
    "def _assess_source_attribution(self, content: str) -> float:\n",
    "    \"\"\"è©•ä¼°ä¾†æºæ¨™è¨»\"\"\"\n",
    "    attribution_indicators = [\n",
    "        r'according\\s+to\\s+\\w+',     # \"according to Smith\"\n",
    "        r'\\w+\\s+states?\\s+that',      # \"Smith states that\"\n",
    "        r'as\\s+reported\\s+by',       # \"as reported by\"\n",
    "        r'source:',                   # \"Source:\"\n",
    "        r'from\\s+\\w+\\s+study',       # \"from ABC study\"\n",
    "        r'based\\s+on\\s+\\w+',         # \"based on research\"\n",
    "    ]\n",
    "    \n",
    "    attribution_count = 0\n",
    "    for pattern in attribution_indicators:\n",
    "        matches = re.findall(pattern, content, re.IGNORECASE)\n",
    "        attribution_count += len(matches)\n",
    "    \n",
    "    # æ¨™æº–åŒ–åˆ†æ•¸\n",
    "    word_count = len(content.split())\n",
    "    attribution_ratio = min(attribution_count / max(1, word_count // 1000), 1.0)\n",
    "    \n",
    "    return attribution_ratio\n",
    "\n",
    "# å°‡æ–¹æ³•æ·»åŠ åˆ° MultiDimensionalQualityAssessor é¡åˆ¥\n",
    "MultiDimensionalQualityAssessor._check_format_consistency = _check_format_consistency\n",
    "MultiDimensionalQualityAssessor._check_terminology_consistency = _check_terminology_consistency\n",
    "MultiDimensionalQualityAssessor._check_writing_style_consistency = _check_writing_style_consistency\n",
    "MultiDimensionalQualityAssessor._assess_document_structure = _assess_document_structure\n",
    "MultiDimensionalQualityAssessor._assess_metadata_completeness = _assess_metadata_completeness\n",
    "MultiDimensionalQualityAssessor._assess_content_coverage = _assess_content_coverage\n",
    "MultiDimensionalQualityAssessor._assess_content_freshness = _assess_content_freshness\n",
    "MultiDimensionalQualityAssessor._assess_paragraph_structure = _assess_paragraph_structure\n",
    "MultiDimensionalQualityAssessor._assess_citations = _assess_citations\n",
    "MultiDimensionalQualityAssessor._assess_source_attribution = _assess_source_attribution\n",
    "\n",
    "print(\"âœ… MultiDimensionalQualityAssessor è¼”åŠ©æ–¹æ³•å®šç¾©å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š ç•°å¸¸æª¢æ¸¬ç³»çµ±\n",
    "\n",
    "### æ©Ÿå™¨å­¸ç¿’é©…å‹•çš„ç•°å¸¸æª¢æ¸¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… QualityAnomalyDetector å®šç¾©å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "class QualityAnomalyDetector:\n",
    "    \"\"\"\n",
    "    å“è³ªç•°å¸¸æª¢æ¸¬ç³»çµ±\n",
    "    ä½¿ç”¨å¤šç¨®æ©Ÿå™¨å­¸ç¿’æŠ€è¡“æª¢æ¸¬å“è³ªæŒ‡æ¨™çš„ç•°å¸¸è®ŠåŒ–\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: AnomalyDetectionConfig):\n",
    "        \"\"\"åˆå§‹åŒ–ç•°å¸¸æª¢æ¸¬å™¨\"\"\"\n",
    "        self.config = config\n",
    "        self.models = {}\n",
    "        self.scalers = {}\n",
    "        self.training_history = []\n",
    "        \n",
    "        # åˆå§‹åŒ–æª¢æ¸¬æ¨¡å‹\n",
    "        self._initialize_models()\n",
    "        \n",
    "        print(f\"âœ… å“è³ªç•°å¸¸æª¢æ¸¬å™¨åˆå§‹åŒ–å®Œæˆ (æ–¹æ³•: {config.method})\")\n",
    "    \n",
    "    def _initialize_models(self):\n",
    "        \"\"\"åˆå§‹åŒ–æª¢æ¸¬æ¨¡å‹\"\"\"\n",
    "        if self.config.method == 'isolation_forest':\n",
    "            self.models['primary'] = IsolationForest(\n",
    "                contamination=self.config.sensitivity,\n",
    "                random_state=42,\n",
    "                n_estimators=100\n",
    "            )\n",
    "        elif self.config.method == 'one_class_svm':\n",
    "            self.models['primary'] = OneClassSVM(\n",
    "                nu=self.config.sensitivity,\n",
    "                kernel='rbf',\n",
    "                gamma='scale'\n",
    "            )\n",
    "        \n",
    "        # è³‡æ–™æ¨™æº–åŒ–å™¨\n",
    "        self.scalers['primary'] = StandardScaler()\n",
    "    \n",
    "    def train_detector(self, quality_data: List[Dict]) -> bool:\n",
    "        \"\"\"\n",
    "        è¨“ç·´ç•°å¸¸æª¢æ¸¬å™¨\n",
    "        \n",
    "        Args:\n",
    "            quality_data: æ­·å²å“è³ªè©•ä¼°è³‡æ–™\n",
    "            \n",
    "        Returns:\n",
    "            bool: è¨“ç·´æ˜¯å¦æˆåŠŸ\n",
    "        \"\"\"\n",
    "        if len(quality_data) < self.config.min_samples:\n",
    "            logger.warning(f\"è¨“ç·´è³‡æ–™ä¸è¶³ ({len(quality_data)} < {self.config.min_samples})\")\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            # æº–å‚™è¨“ç·´è³‡æ–™\n",
    "            training_features = self._prepare_features(quality_data)\n",
    "            \n",
    "            if training_features.empty:\n",
    "                logger.error(\"ç„¡æ³•æå–è¨“ç·´ç‰¹å¾µ\")\n",
    "                return False\n",
    "            \n",
    "            # æ¨™æº–åŒ–ç‰¹å¾µ\n",
    "            X_scaled = self.scalers['primary'].fit_transform(training_features)\n",
    "            \n",
    "            # è¨“ç·´ä¸»æ¨¡å‹\n",
    "            if self.config.method in ['isolation_forest', 'one_class_svm']:\n",
    "                self.models['primary'].fit(X_scaled)\n",
    "            \n",
    "            # è¨˜éŒ„è¨“ç·´æ­·å²\n",
    "            self.training_history.append({\n",
    "                'timestamp': datetime.now(),\n",
    "                'sample_count': len(quality_data),\n",
    "                'feature_count': training_features.shape[1],\n",
    "                'method': self.config.method,\n",
    "                'sensitivity': self.config.sensitivity\n",
    "            })\n",
    "            \n",
    "            print(f\"âœ… ç•°å¸¸æª¢æ¸¬å™¨è¨“ç·´å®Œæˆ (æ¨£æœ¬: {len(quality_data)}, ç‰¹å¾µ: {training_features.shape[1]})\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"ç•°å¸¸æª¢æ¸¬å™¨è¨“ç·´å¤±æ•—: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def detect_anomalies(self, new_quality_data: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        æª¢æ¸¬å“è³ªç•°å¸¸\n",
    "        \n",
    "        Args:\n",
    "            new_quality_data: æ–°çš„å“è³ªè©•ä¼°è³‡æ–™\n",
    "            \n",
    "        Returns:\n",
    "            List[Dict]: æª¢æ¸¬åˆ°çš„ç•°å¸¸åˆ—è¡¨\n",
    "        \"\"\"\n",
    "        if not hasattr(self.models['primary'], 'predict'):\n",
    "            logger.warning(\"æª¢æ¸¬å™¨å°šæœªè¨“ç·´ï¼Œç„¡æ³•æª¢æ¸¬ç•°å¸¸\")\n",
    "            return []\n",
    "        \n",
    "        anomalies = []\n",
    "        \n",
    "        try:\n",
    "            # æº–å‚™æª¢æ¸¬ç‰¹å¾µ\n",
    "            detection_features = self._prepare_features(new_quality_data)\n",
    "            \n",
    "            if detection_features.empty:\n",
    "                return anomalies\n",
    "            \n",
    "            # æ¨™æº–åŒ–ç‰¹å¾µ\n",
    "            X_scaled = self.scalers['primary'].transform(detection_features)\n",
    "            \n",
    "            # åŸ·è¡Œç•°å¸¸æª¢æ¸¬\n",
    "            if self.config.method in ['isolation_forest', 'one_class_svm']:\n",
    "                predictions = self.models['primary'].predict(X_scaled)\n",
    "                anomaly_scores = self.models['primary'].score_samples(X_scaled)\n",
    "                \n",
    "                # è™•ç†ç•°å¸¸æª¢æ¸¬çµæœ\n",
    "                for i, (prediction, score) in enumerate(zip(predictions, anomaly_scores)):\n",
    "                    if prediction == -1:  # ç•°å¸¸æ¨£æœ¬\n",
    "                        quality_record = new_quality_data[i]\n",
    "                        \n",
    "                        # åˆ†æç•°å¸¸åŸå› \n",
    "                        anomaly_details = self._analyze_anomaly(\n",
    "                            quality_record, detection_features.iloc[i], score\n",
    "                        )\n",
    "                        \n",
    "                        anomalies.append({\n",
    "                            'document_id': quality_record.get('document_id'),\n",
    "                            'assessment_id': quality_record.get('assessment_id'),\n",
    "                            'anomaly_score': abs(score),\n",
    "                            'detection_method': self.config.method,\n",
    "                            'detected_at': datetime.now(),\n",
    "                            'details': anomaly_details\n",
    "                        })\n",
    "            \n",
    "            # çµ±è¨ˆæª¢æ¸¬\n",
    "            statistical_anomalies = self._detect_statistical_anomalies(new_quality_data)\n",
    "            anomalies.extend(statistical_anomalies)\n",
    "            \n",
    "            print(f\"ğŸ” æª¢æ¸¬å®Œæˆï¼šç™¼ç¾ {len(anomalies)} å€‹ç•°å¸¸\")\n",
    "            return anomalies\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"ç•°å¸¸æª¢æ¸¬å¤±æ•—: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def _prepare_features(self, quality_data: List[Dict]) -> pd.DataFrame:\n",
    "        \"\"\"æº–å‚™ç‰¹å¾µå‘é‡\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        for record in quality_data:\n",
    "            feature_vector = {\n",
    "                'accuracy': record.get('accuracy_score', 0.0),\n",
    "                'completeness': record.get('completeness_score', 0.0),\n",
    "                'consistency': record.get('consistency_score', 0.0),\n",
    "                'currency': record.get('currency_score', 0.0),\n",
    "                'understandability': record.get('understandability_score', 0.0),\n",
    "                'traceability': record.get('traceability_score', 0.0),\n",
    "                'overall': record.get('overall_score', 0.0)\n",
    "            }\n",
    "            \n",
    "            # æ·»åŠ è¡ç”Ÿç‰¹å¾µ\n",
    "            if self.config.enable_multivariate:\n",
    "                # ç¶­åº¦é–“çš„æ¯”ç‡\n",
    "                feature_vector['acc_comp_ratio'] = (\n",
    "                    feature_vector['accuracy'] / max(feature_vector['completeness'], 0.01)\n",
    "                )\n",
    "                feature_vector['cons_under_ratio'] = (\n",
    "                    feature_vector['consistency'] / max(feature_vector['understandability'], 0.01)\n",
    "                )\n",
    "                \n",
    "                # å“è³ªæ–¹å·®\n",
    "                scores = [\n",
    "                    feature_vector['accuracy'], feature_vector['completeness'],\n",
    "                    feature_vector['consistency'], feature_vector['currency'],\n",
    "                    feature_vector['understandability'], feature_vector['traceability']\n",
    "                ]\n",
    "                feature_vector['score_variance'] = np.var(scores)\n",
    "                feature_vector['score_range'] = max(scores) - min(scores)\n",
    "            \n",
    "            features.append(feature_vector)\n",
    "        \n",
    "        return pd.DataFrame(features)\n",
    "    \n",
    "    def _analyze_anomaly(self, quality_record: Dict, features: pd.Series, anomaly_score: float) -> Dict:\n",
    "        \"\"\"åˆ†æç•°å¸¸åŸå› \"\"\"\n",
    "        details = {\n",
    "            'anomaly_type': 'ml_detected',\n",
    "            'severity': self._calculate_severity(anomaly_score),\n",
    "            'affected_dimensions': [],\n",
    "            'explanation': []\n",
    "        }\n",
    "        \n",
    "        # åˆ†æå„ç¶­åº¦ç•°å¸¸\n",
    "        dimension_scores = {\n",
    "            'accuracy': features.get('accuracy', 0),\n",
    "            'completeness': features.get('completeness', 0),\n",
    "            'consistency': features.get('consistency', 0),\n",
    "            'currency': features.get('currency', 0),\n",
    "            'understandability': features.get('understandability', 0),\n",
    "            'traceability': features.get('traceability', 0)\n",
    "        }\n",
    "        \n",
    "        # è­˜åˆ¥ç•°å¸¸ç¶­åº¦\n",
    "        for dimension, score in dimension_scores.items():\n",
    "            if score < 0.3:  # æ¥µä½åˆ†æ•¸\n",
    "                details['affected_dimensions'].append(dimension)\n",
    "                details['explanation'].append(f\"{dimension} åˆ†æ•¸ç•°å¸¸åä½ ({score:.3f})\")\n",
    "            elif score > 0.95:  # ç•°å¸¸é«˜åˆ†\n",
    "                details['affected_dimensions'].append(dimension)\n",
    "                details['explanation'].append(f\"{dimension} åˆ†æ•¸ç•°å¸¸åé«˜ ({score:.3f})\")\n",
    "        \n",
    "        # æª¢æŸ¥åˆ†æ•¸è®Šç•°æ€§\n",
    "        if 'score_variance' in features and features['score_variance'] > 0.1:\n",
    "            details['explanation'].append(f\"å“è³ªç¶­åº¦é–“è®Šç•°æ€§éå¤§ ({features['score_variance']:.3f})\")\n",
    "        \n",
    "        return details\n",
    "    \n",
    "    def _detect_statistical_anomalies(self, quality_data: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"çµ±è¨ˆæ–¹æ³•æª¢æ¸¬ç•°å¸¸\"\"\"\n",
    "        anomalies = []\n",
    "        \n",
    "        if len(quality_data) < 3:\n",
    "            return anomalies\n",
    "        \n",
    "        # æå–æ•´é«”åˆ†æ•¸\n",
    "        overall_scores = [record.get('overall_score', 0.0) for record in quality_data]\n",
    "        \n",
    "        # Z-Score æª¢æ¸¬\n",
    "        if len(overall_scores) >= 5:\n",
    "            mean_score = np.mean(overall_scores)\n",
    "            std_score = np.std(overall_scores)\n",
    "            \n",
    "            if std_score > 0:\n",
    "                for i, (record, score) in enumerate(zip(quality_data, overall_scores)):\n",
    "                    z_score = abs((score - mean_score) / std_score)\n",
    "                    \n",
    "                    if z_score > 2.5:  # 2.5 æ¨™æº–å·®ä»¥å¤–è¦–ç‚ºç•°å¸¸\n",
    "                        anomalies.append({\n",
    "                            'document_id': record.get('document_id'),\n",
    "                            'assessment_id': record.get('assessment_id'),\n",
    "                            'anomaly_score': z_score,\n",
    "                            'detection_method': 'z_score',\n",
    "                            'detected_at': datetime.now(),\n",
    "                            'details': {\n",
    "                                'anomaly_type': 'statistical',\n",
    "                                'severity': 'high' if z_score > 3.0 else 'medium',\n",
    "                                'z_score': z_score,\n",
    "                                'expected_range': (mean_score - 2*std_score, mean_score + 2*std_score),\n",
    "                                'actual_value': score\n",
    "                            }\n",
    "                        })\n",
    "        \n",
    "        return anomalies\n",
    "    \n",
    "    def _calculate_severity(self, anomaly_score: float) -> str:\n",
    "        \"\"\"è¨ˆç®—ç•°å¸¸åš´é‡ç¨‹åº¦\"\"\"\n",
    "        abs_score = abs(anomaly_score)\n",
    "        \n",
    "        if abs_score > 0.8:\n",
    "            return 'critical'\n",
    "        elif abs_score > 0.6:\n",
    "            return 'high'\n",
    "        elif abs_score > 0.4:\n",
    "            return 'medium'\n",
    "        else:\n",
    "            return 'low'\n",
    "    \n",
    "    def get_detector_stats(self) -> Dict:\n",
    "        \"\"\"ç²å–æª¢æ¸¬å™¨çµ±è¨ˆè³‡è¨Š\"\"\"\n",
    "        return {\n",
    "            'method': self.config.method,\n",
    "            'sensitivity': self.config.sensitivity,\n",
    "            'min_samples': self.config.min_samples,\n",
    "            'training_history_count': len(self.training_history),\n",
    "            'last_training': self.training_history[-1] if self.training_history else None,\n",
    "            'is_trained': hasattr(self.models.get('primary', {}), 'predict')\n",
    "        }\n",
    "\n",
    "print(\"âœ… QualityAnomalyDetector å®šç¾©å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§ª å®Œæ•´æ¸¬è©¦èˆ‡é©—è­‰\n",
    "\n",
    "### å»ºç«‹æ¸¬è©¦ç’°å¢ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨­å®šæ¸¬è©¦ç’°å¢ƒ\n",
    "test_dir = PROJECT_ROOT / 'notebooks' / '03_quality_control' / 'test_data'\n",
    "test_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"ğŸ“‚ æ¸¬è©¦ç›®éŒ„: {test_dir}\")\n",
    "\n",
    "# å»ºç«‹æ›´å¤šæ¨£åŒ–çš„æ¸¬è©¦æ–‡æª”ï¼ˆ8å€‹æ–‡æª”ç¢ºä¿è¶³å¤ æ¨£æœ¬ï¼‰\n",
    "test_documents = {\n",
    "    'high_quality_paper.txt': \"\"\"\n",
    "A Comprehensive Analysis of Machine Learning Applications in Healthcare\n",
    "\n",
    "Abstract\n",
    "This study presents a thorough examination of machine learning applications in healthcare systems. We analyze over 500 implementations across various medical domains and provide evidence-based recommendations for future deployment. Our findings indicate a 35% improvement in diagnostic accuracy when ML systems are properly integrated.\n",
    "\n",
    "1. Introduction\n",
    "Machine learning has emerged as a transformative technology in healthcare, offering unprecedented opportunities for improving patient outcomes. According to recent studies (Smith et al., 2023), the integration of AI systems has shown remarkable success in diagnostic imaging, drug discovery, and personalized medicine.\n",
    "\n",
    "The healthcare industry generates approximately 2.5 quintillion bytes of data daily (Johnson, 2023). This vast amount of information presents both opportunities and challenges for healthcare providers seeking to leverage data-driven insights.\n",
    "\n",
    "2. Methodology\n",
    "We conducted a systematic literature review of peer-reviewed publications from 2020 to 2023. Our search strategy included multiple databases: PubMed, IEEE Xplore, and ACM Digital Library. We identified 847 relevant studies and selected 156 for detailed analysis based on our inclusion criteria.\n",
    "\n",
    "3. Results\n",
    "Our analysis reveals three primary categories of ML applications: diagnostic systems (45%), predictive analytics (35%), and treatment optimization (20%). Diagnostic systems showed the highest success rates, with average accuracy improvements of 28% compared to traditional methods.\n",
    "\n",
    "4. Discussion\n",
    "The implementation of machine learning in healthcare requires careful consideration of ethical implications, data privacy, and regulatory compliance. Our findings suggest that successful deployments require interdisciplinary collaboration between technologists and healthcare professionals.\n",
    "\n",
    "5. Conclusion\n",
    "Machine learning represents a significant advancement in healthcare technology. With proper implementation and ongoing evaluation, these systems can substantially improve patient care quality and operational efficiency.\n",
    "\n",
    "References\n",
    "[1] Smith, J., et al. (2023). \"AI in Medical Diagnosis.\" Nature Medicine, 15(3), 245-267.\n",
    "[2] Johnson, M. (2023). \"Healthcare Data Analytics.\" JAMA, 180(12), 1234-1245.\n",
    "\"\"\",\n",
    "    \n",
    "    'medium_quality_report.txt': \"\"\"\n",
    "Quarterly Business Review Q3 2024\n",
    "\n",
    "Executive Summary\n",
    "This report covers our business performance for Q3 2024. Revenue was good and we met most targets. There were some challenges but overall things went well.\n",
    "\n",
    "Financial Results\n",
    "Revenue was $2.5M which is up from last quarter. Costs were controlled and we made a profit. The sales team did well and we got new customers.\n",
    "\n",
    "Operations\n",
    "Operations ran smoothly most of the time. We had some issues with the new system but they were resolved quickly. Staff worked hard and productivity was ok.\n",
    "\n",
    "Marketing\n",
    "Marketing campaigns performed adequately. We got some leads and conversion rates were reasonable. Social media engagement was standard.\n",
    "\n",
    "Recommendations\n",
    "We should continue current strategies and maybe improve some processes. Training might help and we could look at new technologies.\n",
    "\"\"\",\n",
    "    \n",
    "    'low_quality_text.txt': \"\"\"\n",
    "AI stuff\n",
    "\n",
    "AI is good. It does things. Machines learn stuff and then they know things. This is useful for business and other things too.\n",
    "\n",
    "There are different kinds of AI like ML and DL and NLP. They all do different stuff but its all related somehow.\n",
    "\n",
    "Companies use AI for various reasons. It helps with efficiency and productivity and other metrics. ROI is important.\n",
    "\n",
    "The future looks bright for AI technology. More companies will adopt it. Training is needed. Ethics are important too but progress shouldnt be slowed down.\n",
    "\n",
    "In conclusion AI is the future and companies should invest in it soon before competitors get ahead.\n",
    "\"\"\",\n",
    "    \n",
    "    'technical_documentation.txt': \"\"\"\n",
    "API Documentation - User Authentication Service v2.1\n",
    "\n",
    "Overview\n",
    "The User Authentication Service provides secure authentication and authorization capabilities for applications. This service implements OAuth 2.0 and JWT token standards with enterprise-grade security features.\n",
    "\n",
    "Authentication Endpoints\n",
    "\n",
    "POST /auth/login\n",
    "Description: Authenticates a user with email/password credentials\n",
    "Parameters:\n",
    "- email (string, required): User's email address\n",
    "- password (string, required): User's password\n",
    "- remember_me (boolean, optional): Extended session duration\n",
    "\n",
    "Response:\n",
    "{\n",
    "  \"access_token\": \"eyJhbGciOiJIUzI1NiIs...\",\n",
    "  \"refresh_token\": \"dGhpcyBpcyBhIHJlZnJlc2g...\",\n",
    "  \"expires_in\": 3600,\n",
    "  \"user_id\": \"12345\"\n",
    "}\n",
    "\n",
    "Error Codes:\n",
    "- 400: Invalid credentials\n",
    "- 401: Account locked\n",
    "- 429: Rate limit exceeded\n",
    "\n",
    "POST /auth/refresh\n",
    "Description: Refreshes an expired access token using a valid refresh token\n",
    "Headers:\n",
    "- Authorization: Bearer {refresh_token}\n",
    "\n",
    "Security Considerations\n",
    "- All endpoints require HTTPS in production\n",
    "- Rate limiting: 5 requests per minute per IP\n",
    "- Token lifetime: 1 hour (access), 30 days (refresh)\n",
    "- Failed login attempts are logged for security monitoring\n",
    "\n",
    "Implementation Example\n",
    "```python\n",
    "import requests\n",
    "\n",
    "response = requests.post('https://api.example.com/auth/login', {\n",
    "    'email': 'user@example.com',\n",
    "    'password': 'secure_password123'\n",
    "})\n",
    "\n",
    "if response.status_code == 200:\n",
    "    tokens = response.json()\n",
    "    access_token = tokens['access_token']\n",
    "```\n",
    "\n",
    "Version History\n",
    "- v2.1 (2024-01-15): Added refresh token rotation\n",
    "- v2.0 (2023-12-01): OAuth 2.0 compliance updates\n",
    "- v1.5 (2023-10-15): Enhanced security features\n",
    "\"\"\",\n",
    "    \n",
    "    'policy_document.txt': \"\"\"\n",
    "Data Privacy and Security Policy\n",
    "\n",
    "Document ID: POL-2024-001\n",
    "Effective Date: January 1, 2024\n",
    "Last Reviewed: October 15, 2024\n",
    "Next Review: January 1, 2025\n",
    "\n",
    "1. Purpose and Scope\n",
    "This policy establishes the framework for protecting personal and sensitive data within our organization. It applies to all employees, contractors, and third-party vendors who handle, process, or have access to organizational data.\n",
    "\n",
    "2. Policy Statement\n",
    "Our organization is committed to protecting the privacy and security of all data entrusted to us. We will implement appropriate technical, administrative, and physical safeguards to ensure data confidentiality, integrity, and availability.\n",
    "\n",
    "3. Data Classification\n",
    "3.1 Public Data: Information that can be freely shared without risk\n",
    "3.2 Internal Data: Information restricted to authorized personnel\n",
    "3.3 Confidential Data: Sensitive information requiring special protection\n",
    "3.4 Restricted Data: Highly sensitive information with strict access controls\n",
    "\n",
    "4. Access Controls\n",
    "- Role-based access control (RBAC) must be implemented\n",
    "- Principle of least privilege applies to all data access\n",
    "- Regular access reviews conducted quarterly\n",
    "- Multi-factor authentication required for sensitive systems\n",
    "\n",
    "5. Data Retention\n",
    "- Personal data retained only as long as necessary for business purposes\n",
    "- Retention schedules established for each data category\n",
    "- Secure deletion procedures implemented for expired data\n",
    "\n",
    "6. Incident Response\n",
    "- Data breaches reported within 72 hours to relevant authorities\n",
    "- Incident response team activated for all security incidents\n",
    "- Post-incident analysis conducted to prevent recurrence\n",
    "\n",
    "7. Training and Awareness\n",
    "- Annual privacy training required for all staff\n",
    "- Regular security awareness communications\n",
    "- Specialized training for data handlers\n",
    "\n",
    "8. Compliance\n",
    "This policy ensures compliance with GDPR, CCPA, and other applicable regulations.\n",
    "\n",
    "Approved by: Chief Information Security Officer\n",
    "Date: January 1, 2024\n",
    "\"\"\",\n",
    "    \n",
    "    'research_proposal.txt': \"\"\"\n",
    "Research Proposal: Quantum Computing Applications in Cryptography\n",
    "\n",
    "Principal Investigator: Dr. Elena Rodriguez\n",
    "Co-Investigators: Prof. James Chen, Dr. Sarah Kim\n",
    "Institution: University of Technology\n",
    "Funding Agency: National Science Foundation\n",
    "Requested Amount: $2,500,000\n",
    "Project Duration: 3 years\n",
    "\n",
    "Abstract\n",
    "This research proposes to investigate the potential applications of quantum computing in modern cryptographic systems. As quantum computers become more powerful, traditional encryption methods face unprecedented challenges. Our research aims to develop quantum-resistant cryptographic algorithms and explore new quantum cryptographic protocols.\n",
    "\n",
    "1. Background and Significance\n",
    "The advent of quantum computing presents both opportunities and threats to cybersecurity. While quantum computers could break existing encryption methods, they also enable new forms of quantum cryptography that offer theoretically unbreakable security.\n",
    "\n",
    "Current RSA and elliptic curve cryptographic systems rely on the computational difficulty of factoring large integers. Shor's algorithm, when implemented on a sufficiently powerful quantum computer, could solve these problems exponentially faster than classical computers.\n",
    "\n",
    "2. Research Objectives\n",
    "2.1 Develop post-quantum cryptographic algorithms resistant to quantum attacks\n",
    "2.2 Investigate quantum key distribution protocols for secure communication\n",
    "2.3 Analyze the security implications of hybrid classical-quantum systems\n",
    "2.4 Create a framework for transitioning from classical to quantum-safe cryptography\n",
    "\n",
    "3. Methodology\n",
    "We will employ both theoretical analysis and experimental validation using quantum simulators. Our approach includes:\n",
    "- Mathematical analysis of quantum algorithms\n",
    "- Security proofs for proposed protocols\n",
    "- Implementation and testing on quantum hardware simulators\n",
    "- Performance comparison with classical methods\n",
    "\n",
    "4. Expected Outcomes\n",
    "- 3-5 peer-reviewed publications in top-tier journals\n",
    "- Development of practical quantum-resistant algorithms\n",
    "- Training of 4 graduate students and 2 postdoctoral researchers\n",
    "- Open-source software library for quantum cryptographic protocols\n",
    "\n",
    "5. Budget Justification\n",
    "Year 1: $900,000 (personnel: $600,000, equipment: $200,000, travel: $50,000, indirect: $50,000)\n",
    "Year 2: $850,000 (personnel: $650,000, supplies: $100,000, travel: $50,000, indirect: $50,000)\n",
    "Year 3: $750,000 (personnel: $600,000, publication: $50,000, travel: $50,000, indirect: $50,000)\n",
    "\n",
    "References\n",
    "[1] Shor, P. W. (1994). \"Algorithms for quantum computation.\" Proc. 35th Annual Symposium on Foundations of Computer Science.\n",
    "[2] Bennett, C. H., & Brassard, G. (1984). \"Quantum cryptography.\" IEEE International Conference on Computers, Systems and Signal Processing.\n",
    "\"\"\",\n",
    "    \n",
    "    'user_manual.txt': \"\"\"\n",
    "SmartHome Controller User Manual\n",
    "\n",
    "Model: SH-2024-Pro\n",
    "Version: 3.2.1\n",
    "Publication Date: March 2024\n",
    "\n",
    "Table of Contents\n",
    "1. Getting Started\n",
    "2. Initial Setup\n",
    "3. Device Configuration\n",
    "4. Advanced Features\n",
    "5. Troubleshooting\n",
    "6. Technical Specifications\n",
    "\n",
    "Chapter 1: Getting Started\n",
    "\n",
    "Welcome to your new SmartHome Controller! This device allows you to control and monitor all connected smart devices in your home from a single interface.\n",
    "\n",
    "What's in the Box:\n",
    "- SmartHome Controller unit\n",
    "- Power adapter (12V, 2A)\n",
    "- Ethernet cable\n",
    "- Quick start guide\n",
    "- Warranty information\n",
    "\n",
    "Safety Precautions:\n",
    "- Do not expose the device to moisture or extreme temperatures\n",
    "- Use only the provided power adapter\n",
    "- Keep the device away from direct sunlight\n",
    "- Ensure proper ventilation around the device\n",
    "\n",
    "Chapter 2: Initial Setup\n",
    "\n",
    "Step 1: Physical Installation\n",
    "1. Choose a central location in your home for optimal wireless coverage\n",
    "2. Connect the power adapter to the device and plug into a wall outlet\n",
    "3. Connect the Ethernet cable to your router (optional but recommended)\n",
    "4. Wait for the LED indicator to turn solid green (approximately 2 minutes)\n",
    "\n",
    "Step 2: Network Configuration\n",
    "1. Download the SmartHome app from the App Store or Google Play\n",
    "2. Create a new account or sign in to your existing account\n",
    "3. Tap \"Add Device\" and select \"SmartHome Controller\"\n",
    "4. Follow the on-screen instructions to connect to your Wi-Fi network\n",
    "\n",
    "Chapter 3: Device Configuration\n",
    "\n",
    "Adding Smart Devices:\n",
    "The controller supports over 200 different smart device types including:\n",
    "- Smart lights and switches\n",
    "- Thermostats and climate controls\n",
    "- Security cameras and sensors\n",
    "- Smart locks and garage door openers\n",
    "- Entertainment systems\n",
    "\n",
    "To add a device:\n",
    "1. Open the SmartHome app\n",
    "2. Tap the \"+\" button in the top right corner\n",
    "3. Select the device type from the list\n",
    "4. Follow the specific pairing instructions for your device\n",
    "\n",
    "Chapter 4: Advanced Features\n",
    "\n",
    "Scene Creation:\n",
    "Create custom scenes to control multiple devices with a single command.\n",
    "\n",
    "Automation Rules:\n",
    "Set up rules to trigger actions based on time, device status, or sensor readings.\n",
    "\n",
    "Voice Control:\n",
    "Compatible with Amazon Alexa, Google Assistant, and Apple HomeKit.\n",
    "\n",
    "Chapter 5: Troubleshooting\n",
    "\n",
    "Common Issues:\n",
    "Q: Device won't connect to Wi-Fi\n",
    "A: Ensure you're using a 2.4GHz network and the password is correct\n",
    "\n",
    "Q: Smart devices not responding\n",
    "A: Check if the devices have power and are within range of the controller\n",
    "\n",
    "Q: App crashes or freezes\n",
    "A: Force close the app and restart it. If the problem persists, reinstall the app.\n",
    "\n",
    "Technical Support:\n",
    "Email: support@smarthome.com\n",
    "Phone: 1-800-SMART-HOME (1-800-762-7846)\n",
    "Hours: Monday-Friday, 8 AM - 8 PM EST\n",
    "\n",
    "Chapter 6: Technical Specifications\n",
    "\n",
    "- Processor: ARM Cortex-A53 Quad-core 1.4GHz\n",
    "- Memory: 2GB RAM, 16GB storage\n",
    "- Connectivity: Wi-Fi 802.11 a/b/g/n/ac, Bluetooth 5.0, Zigbee 3.0, Z-Wave Plus\n",
    "- Operating Temperature: 32Â°F to 95Â°F (0Â°C to 35Â°C)\n",
    "- Dimensions: 6\" x 4\" x 1.5\" (152mm x 102mm x 38mm)\n",
    "- Power Consumption: 12W maximum\n",
    "\"\"\",\n",
    "    \n",
    "    'financial_analysis.txt': \"\"\"\n",
    "Quarterly Financial Analysis - Q3 2024\n",
    "TechCorp Industries\n",
    "\n",
    "Executive Summary\n",
    "TechCorp Industries demonstrated strong financial performance in Q3 2024, with revenue growth of 18% year-over-year and improved profit margins across all business segments. This analysis examines key financial metrics, market trends, and strategic implications for the remainder of 2024.\n",
    "\n",
    "Revenue Analysis\n",
    "Total revenue for Q3 2024 reached $127.3 million, representing an 18% increase compared to Q3 2023 ($107.8 million) and a 12% increase from Q2 2024 ($113.7 million).\n",
    "\n",
    "Revenue by Segment:\n",
    "- Software Solutions: $78.2M (61% of total revenue, +22% YoY)\n",
    "- Hardware Products: $31.4M (25% of total revenue, +8% YoY)\n",
    "- Professional Services: $17.7M (14% of total revenue, +15% YoY)\n",
    "\n",
    "The software segment continues to drive growth, benefiting from increased demand for cloud-based solutions and subscription services. Hardware revenue growth was modest due to supply chain constraints, while professional services showed steady improvement.\n",
    "\n",
    "Profitability Metrics\n",
    "Gross profit margin improved to 64.2% in Q3 2024, up from 61.8% in Q3 2023. This improvement reflects operational efficiencies and favorable product mix shifts toward higher-margin software offerings.\n",
    "\n",
    "Operating expenses increased 12% year-over-year to $52.6 million, primarily due to:\n",
    "- Research and development investments: $23.1M (+15% YoY)\n",
    "- Sales and marketing: $18.8M (+10% YoY)  \n",
    "- General and administrative: $10.7M (+8% YoY)\n",
    "\n",
    "Net income reached $28.4 million, or $1.42 per diluted share, compared to $22.1 million, or $1.12 per diluted share in Q3 2023.\n",
    "\n",
    "Cash Flow and Balance Sheet\n",
    "Operating cash flow was $35.7 million in Q3 2024, compared to $28.9 million in Q3 2023. The company ended the quarter with $156.2 million in cash and cash equivalents.\n",
    "\n",
    "Key balance sheet highlights:\n",
    "- Total assets: $487.3M (+8% from Q2 2024)\n",
    "- Total debt: $89.4M (debt-to-equity ratio of 0.23)\n",
    "- Shareholders' equity: $389.1M\n",
    "\n",
    "Market Position and Competition\n",
    "TechCorp maintains a strong competitive position in its core markets. Market share in the enterprise software segment increased to 12.3%, up from 11.7% in the previous year. The company's customer retention rate remains high at 94%.\n",
    "\n",
    "Key competitive advantages include:\n",
    "- Proprietary technology platform with high switching costs\n",
    "- Strong customer relationships and brand recognition\n",
    "- Comprehensive product portfolio addressing multiple market segments\n",
    "\n",
    "Risk Factors and Challenges\n",
    "Several factors could impact future performance:\n",
    "- Economic uncertainty affecting enterprise technology spending\n",
    "- Intensifying competition from both established players and startups\n",
    "- Cybersecurity threats and data privacy regulations\n",
    "- Talent acquisition and retention in competitive labor markets\n",
    "\n",
    "Outlook and Guidance\n",
    "Based on current market conditions and pipeline visibility, management reaffirms full-year 2024 guidance:\n",
    "- Revenue: $495M - $505M (previous guidance: $490M - $510M)\n",
    "- Operating margin: 21% - 23%\n",
    "- Diluted EPS: $5.40 - $5.60\n",
    "\n",
    "For Q4 2024, the company expects:\n",
    "- Revenue: $130M - $135M\n",
    "- Operating margin: 22% - 24%\n",
    "\n",
    "Strategic Initiatives\n",
    "Key strategic priorities for the remainder of 2024 include:\n",
    "1. Accelerating cloud migration for existing customers\n",
    "2. Expanding international presence in European markets\n",
    "3. Investing in artificial intelligence and machine learning capabilities\n",
    "4. Pursuing strategic acquisitions to enhance product portfolio\n",
    "\n",
    "Conclusion\n",
    "TechCorp's Q3 2024 performance demonstrates the effectiveness of its strategic focus on high-margin software solutions and operational excellence. The company is well-positioned for continued growth, though management remains cautious about macroeconomic headwinds.\n",
    "\n",
    "Analyst: Jennifer Walsh, CFA\n",
    "Date: October 28, 2024\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "# å»ºç«‹æ¸¬è©¦æª”æ¡ˆ\n",
    "for filename, content in test_documents.items():\n",
    "    file_path = test_dir / filename\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(f\"âœ… å»ºç«‹äº† {len(test_documents)} å€‹æ¸¬è©¦æ–‡æª”\")\n",
    "\n",
    "# æº–å‚™æ¸¬è©¦å…ƒè³‡æ–™\n",
    "test_metadata = {\n",
    "    'high_quality_paper.txt': {\n",
    "        'title': 'A Comprehensive Analysis of Machine Learning Applications in Healthcare',\n",
    "        'authors': ['Dr. Sarah Chen', 'Prof. Michael Rodriguez'],\n",
    "        'created_date': '2024-01-15T10:30:00Z',\n",
    "        'document_type': 'academic_paper',\n",
    "        'organization': 'Stanford Medical School',\n",
    "        'keywords': ['machine learning', 'healthcare', 'diagnostic systems'],\n",
    "        'version': '1.0'\n",
    "    },\n",
    "    'medium_quality_report.txt': {\n",
    "        'title': 'Quarterly Business Review Q3 2024',\n",
    "        'authors': ['Business Team'],\n",
    "        'created_date': '2024-10-01T09:00:00Z',\n",
    "        'document_type': 'business_report',\n",
    "        'organization': 'Tech Corp',\n",
    "        'keywords': ['quarterly review', 'business performance']\n",
    "    },\n",
    "    'low_quality_text.txt': {\n",
    "        'title': 'AI stuff',\n",
    "        'created_date': '2024-11-01T14:30:00Z',\n",
    "        'document_type': 'other'\n",
    "    },\n",
    "    'technical_documentation.txt': {\n",
    "        'title': 'API Documentation - User Authentication Service v2.1',\n",
    "        'authors': ['DevOps Team'],\n",
    "        'created_date': '2024-01-15T16:45:00Z',\n",
    "        'document_type': 'technical_doc',\n",
    "        'organization': 'Engineering Dept',\n",
    "        'keywords': ['API', 'authentication', 'OAuth'],\n",
    "        'version': '2.1'\n",
    "    },\n",
    "    'policy_document.txt': {\n",
    "        'title': 'Data Privacy and Security Policy',\n",
    "        'authors': ['Legal Department', 'IT Security Team'],\n",
    "        'created_date': '2024-01-01T00:00:00Z',\n",
    "        'document_type': 'policy',\n",
    "        'organization': 'Corporate',\n",
    "        'keywords': ['data privacy', 'security', 'GDPR', 'compliance'],\n",
    "        'version': 'POL-2024-001'\n",
    "    },\n",
    "    'research_proposal.txt': {\n",
    "        'title': 'Research Proposal: Quantum Computing Applications in Cryptography',\n",
    "        'authors': ['Dr. Elena Rodriguez', 'Prof. James Chen', 'Dr. Sarah Kim'],\n",
    "        'created_date': '2024-02-15T09:30:00Z',\n",
    "        'document_type': 'academic_paper',\n",
    "        'organization': 'University of Technology',\n",
    "        'keywords': ['quantum computing', 'cryptography', 'research'],\n",
    "        'version': '1.0'\n",
    "    },\n",
    "    'user_manual.txt': {\n",
    "        'title': 'SmartHome Controller User Manual',\n",
    "        'authors': ['Technical Writing Team'],\n",
    "        'created_date': '2024-03-01T10:00:00Z',\n",
    "        'document_type': 'technical_doc',\n",
    "        'organization': 'SmartHome Inc',\n",
    "        'keywords': ['user manual', 'smart home', 'installation'],\n",
    "        'version': '3.2.1'\n",
    "    },\n",
    "    'financial_analysis.txt': {\n",
    "        'title': 'Quarterly Financial Analysis - Q3 2024',\n",
    "        'authors': ['Jennifer Walsh'],\n",
    "        'created_date': '2024-10-28T14:00:00Z',\n",
    "        'document_type': 'business_report',\n",
    "        'organization': 'TechCorp Industries',\n",
    "        'keywords': ['financial analysis', 'quarterly report', 'revenue'],\n",
    "        'version': 'Q3-2024'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"âœ… æ¸¬è©¦å…ƒè³‡æ–™æº–å‚™å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åŸ·è¡Œå“è³ªè©•ä¼°æ¸¬è©¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ é–‹å§‹å“è³ªè©•ä¼°æ¸¬è©¦\n",
      "\n",
      "âš ï¸  LanguageTool åˆå§‹åŒ–å¤±æ•—: Detected java 11.0. LanguageTool requires Java >= 17 for version latest.\n",
      "âœ… SpellChecker åˆå§‹åŒ–å®Œæˆ\n",
      "âœ… å¤šç¶­åº¦å“è³ªè©•ä¼°å™¨åˆå§‹åŒ–å®Œæˆ\n",
      "ğŸ“Š è©•ä¼°æ–‡æª”: high_quality_paper.txt\n",
      "  å“è³ªç‹€æ…‹: GOOD\n",
      "  ç¶œåˆåˆ†æ•¸: 0.713\n",
      "  æº–ç¢ºæ€§: 0.843\n",
      "  å®Œæ•´æ€§: 0.920\n",
      "  ä¸€è‡´æ€§: 0.468\n",
      "  æ™‚æ•ˆæ€§: 0.650\n",
      "  å¯ç†è§£æ€§: 0.381\n",
      "  å¯è¿½æº¯æ€§: 0.900\n",
      "\n",
      "ğŸ“Š è©•ä¼°æ–‡æª”: medium_quality_report.txt\n",
      "  å“è³ªç‹€æ…‹: FAIR\n",
      "  ç¶œåˆåˆ†æ•¸: 0.660\n",
      "  æº–ç¢ºæ€§: 0.908\n",
      "  å®Œæ•´æ€§: 0.762\n",
      "  ä¸€è‡´æ€§: 0.776\n",
      "  æ™‚æ•ˆæ€§: 0.650\n",
      "  å¯ç†è§£æ€§: 0.544\n",
      "  å¯è¿½æº¯æ€§: 0.200\n",
      "\n",
      "ğŸ“Š è©•ä¼°æ–‡æª”: low_quality_text.txt\n",
      "  å“è³ªç‹€æ…‹: FAIR\n",
      "  ç¶œåˆåˆ†æ•¸: 0.537\n",
      "  æº–ç¢ºæ€§: 0.720\n",
      "  å®Œæ•´æ€§: 0.556\n",
      "  ä¸€è‡´æ€§: 0.668\n",
      "  æ™‚æ•ˆæ€§: 0.500\n",
      "  å¯ç†è§£æ€§: 0.610\n",
      "  å¯è¿½æº¯æ€§: 0.100\n",
      "\n",
      "ğŸ“Š è©•ä¼°æ–‡æª”: technical_documentation.txt\n",
      "  å“è³ªç‹€æ…‹: FAIR\n",
      "  ç¶œåˆåˆ†æ•¸: 0.527\n",
      "  æº–ç¢ºæ€§: 0.700\n",
      "  å®Œæ•´æ€§: 0.729\n",
      "  ä¸€è‡´æ€§: 0.000\n",
      "  æ™‚æ•ˆæ€§: 0.650\n",
      "  å¯ç†è§£æ€§: 0.306\n",
      "  å¯è¿½æº¯æ€§: 0.650\n",
      "\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š å“è³ªè©•ä¼°æ‘˜è¦\n",
      "                     æ–‡æª”              é¡å‹  å­—æ•¸  ç¶œåˆåˆ†æ•¸   ç‹€æ…‹  æº–ç¢ºæ€§  å®Œæ•´æ€§  ä¸€è‡´æ€§  æ™‚æ•ˆæ€§ å¯ç†è§£æ€§ å¯è¿½æº¯æ€§\n",
      "     high_quality_paper  academic_paper 298 0.713 good 0.84 0.92 0.47 0.65 0.38 0.90\n",
      "  medium_quality_report business_report 130 0.660 fair 0.91 0.76 0.78 0.65 0.54 0.20\n",
      "       low_quality_text           other 107 0.537 fair 0.72 0.56 0.67 0.50 0.61 0.10\n",
      "technical_documentation   technical_doc 192 0.527 fair 0.70 0.73 0.00 0.65 0.31 0.65\n",
      "\n",
      "ğŸ“ˆ çµ±è¨ˆåˆ†æ:\n",
      "å¹³å‡å“è³ªåˆ†æ•¸: 0.609\n",
      "æ¨™æº–å·®: 0.079\n",
      "æœ€é«˜åˆ†æ•¸: 0.713\n",
      "æœ€ä½åˆ†æ•¸: 0.527\n",
      "\n",
      "ğŸ¯ å“è³ªç‹€æ…‹åˆ†ä½ˆ:\n",
      "Good: 1 å€‹æ–‡æª”\n",
      "Fair: 3 å€‹æ–‡æª”\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ”„ é–‹å§‹å“è³ªè©•ä¼°æ¸¬è©¦\\n\")\n",
    "\n",
    "# åˆå§‹åŒ–å“è³ªè©•ä¼°å™¨\n",
    "quality_assessor = MultiDimensionalQualityAssessor()\n",
    "\n",
    "# è©•ä¼°æ‰€æœ‰æ¸¬è©¦æ–‡æª”\n",
    "assessment_results = []\n",
    "\n",
    "for filename in test_documents.keys():\n",
    "    file_path = test_dir / filename\n",
    "    \n",
    "    # è®€å–æ–‡æª”å…§å®¹\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # ç²å–å…ƒè³‡æ–™\n",
    "    metadata = test_metadata.get(filename, {})\n",
    "    \n",
    "    # åŸ·è¡Œå“è³ªè©•ä¼°\n",
    "    print(f\"ğŸ“Š è©•ä¼°æ–‡æª”: {filename}\")\n",
    "    quality_metrics = quality_assessor.assess_document_quality(content, metadata)\n",
    "    \n",
    "    # è¨˜éŒ„çµæœ\n",
    "    result = {\n",
    "        'filename': filename,\n",
    "        'document_type': metadata.get('document_type', 'unknown'),\n",
    "        'word_count': len(content.split()),\n",
    "        'quality_metrics': quality_metrics,\n",
    "        'quality_status': quality_metrics.get_status().value,\n",
    "        'assessment_time': datetime.now()\n",
    "    }\n",
    "    \n",
    "    assessment_results.append(result)\n",
    "    \n",
    "    # é¡¯ç¤ºè©•ä¼°çµæœ\n",
    "    print(f\"  å“è³ªç‹€æ…‹: {result['quality_status'].upper()}\")\n",
    "    print(f\"  ç¶œåˆåˆ†æ•¸: {quality_metrics.overall_score:.3f}\")\n",
    "    print(f\"  æº–ç¢ºæ€§: {quality_metrics.accuracy:.3f}\")\n",
    "    print(f\"  å®Œæ•´æ€§: {quality_metrics.completeness:.3f}\")\n",
    "    print(f\"  ä¸€è‡´æ€§: {quality_metrics.consistency:.3f}\")\n",
    "    print(f\"  æ™‚æ•ˆæ€§: {quality_metrics.currency:.3f}\")\n",
    "    print(f\"  å¯ç†è§£æ€§: {quality_metrics.understandability:.3f}\")\n",
    "    print(f\"  å¯è¿½æº¯æ€§: {quality_metrics.traceability:.3f}\")\n",
    "    print()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š å“è³ªè©•ä¼°æ‘˜è¦\")\n",
    "\n",
    "# å»ºç«‹è©•ä¼°æ‘˜è¦\n",
    "summary_data = []\n",
    "for result in assessment_results:\n",
    "    metrics = result['quality_metrics']\n",
    "    summary_data.append({\n",
    "        'æ–‡æª”': result['filename'].replace('.txt', ''),\n",
    "        'é¡å‹': result['document_type'],\n",
    "        'å­—æ•¸': result['word_count'],\n",
    "        'ç¶œåˆåˆ†æ•¸': f\"{metrics.overall_score:.3f}\",\n",
    "        'ç‹€æ…‹': result['quality_status'],\n",
    "        'æº–ç¢ºæ€§': f\"{metrics.accuracy:.2f}\",\n",
    "        'å®Œæ•´æ€§': f\"{metrics.completeness:.2f}\",\n",
    "        'ä¸€è‡´æ€§': f\"{metrics.consistency:.2f}\",\n",
    "        'æ™‚æ•ˆæ€§': f\"{metrics.currency:.2f}\",\n",
    "        'å¯ç†è§£æ€§': f\"{metrics.understandability:.2f}\",\n",
    "        'å¯è¿½æº¯æ€§': f\"{metrics.traceability:.2f}\"\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# çµ±è¨ˆåˆ†æ\n",
    "overall_scores = [result['quality_metrics'].overall_score for result in assessment_results]\n",
    "print(f\"\\nğŸ“ˆ çµ±è¨ˆåˆ†æ:\")\n",
    "print(f\"å¹³å‡å“è³ªåˆ†æ•¸: {np.mean(overall_scores):.3f}\")\n",
    "print(f\"æ¨™æº–å·®: {np.std(overall_scores):.3f}\")\n",
    "print(f\"æœ€é«˜åˆ†æ•¸: {max(overall_scores):.3f}\")\n",
    "print(f\"æœ€ä½åˆ†æ•¸: {min(overall_scores):.3f}\")\n",
    "\n",
    "# å“è³ªç‹€æ…‹åˆ†ä½ˆ\n",
    "status_counts = {}\n",
    "for result in assessment_results:\n",
    "    status = result['quality_status']\n",
    "    status_counts[status] = status_counts.get(status, 0) + 1\n",
    "\n",
    "print(f\"\\nğŸ¯ å“è³ªç‹€æ…‹åˆ†ä½ˆ:\")\n",
    "for status, count in status_counts.items():\n",
    "    print(f\"{status.capitalize()}: {count} å€‹æ–‡æª”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å“è³ªè©•ä¼°çµæœè¦–è¦ºåŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ç”Ÿæˆå“è³ªè©•ä¼°è¦–è¦ºåŒ–åœ–è¡¨\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "fill": "toself",
         "line": {
          "color": "blue"
         },
         "name": "high quality paper",
         "r": [
          0.8431372549019608,
          0.9198955018768341,
          0.4679677584182303,
          0.6499999999999999,
          0.38134069351230443,
          0.9,
          0.8431372549019608
         ],
         "theta": [
          "æº–ç¢ºæ€§",
          "å®Œæ•´æ€§",
          "ä¸€è‡´æ€§",
          "æ™‚æ•ˆæ€§",
          "å¯ç†è§£æ€§",
          "å¯è¿½æº¯æ€§",
          "æº–ç¢ºæ€§"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "line": {
          "color": "red"
         },
         "name": "medium quality report",
         "r": [
          0.9083969465648856,
          0.7618591136409116,
          0.776197140870088,
          0.6499999999999999,
          0.54386358974359,
          0.2,
          0.9083969465648856
         ],
         "theta": [
          "æº–ç¢ºæ€§",
          "å®Œæ•´æ€§",
          "ä¸€è‡´æ€§",
          "æ™‚æ•ˆæ€§",
          "å¯ç†è§£æ€§",
          "å¯è¿½æº¯æ€§",
          "æº–ç¢ºæ€§"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "line": {
          "color": "green"
         },
         "name": "low quality text",
         "r": [
          0.719626168224299,
          0.5555845036913614,
          0.6676726826572916,
          0.5,
          0.6096564619492657,
          0.1,
          0.719626168224299
         ],
         "theta": [
          "æº–ç¢ºæ€§",
          "å®Œæ•´æ€§",
          "ä¸€è‡´æ€§",
          "æ™‚æ•ˆæ€§",
          "å¯ç†è§£æ€§",
          "å¯è¿½æº¯æ€§",
          "æº–ç¢ºæ€§"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "line": {
          "color": "orange"
         },
         "name": "technical documentation",
         "r": [
          0.7,
          0.72944016382714,
          0,
          0.6499999999999999,
          0.3064,
          0.65,
          0.7
         ],
         "theta": [
          "æº–ç¢ºæ€§",
          "å®Œæ•´æ€§",
          "ä¸€è‡´æ€§",
          "æ™‚æ•ˆæ€§",
          "å¯ç†è§£æ€§",
          "å¯è¿½æº¯æ€§",
          "æº–ç¢ºæ€§"
         ],
         "type": "scatterpolar"
        }
       ],
       "layout": {
        "height": 600,
        "polar": {
         "radialaxis": {
          "range": [
           0,
           1
          ],
          "visible": true
         }
        },
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "æ–‡æª”å“è³ªå¤šç¶­åº¦é›·é”åœ–"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "æº–ç¢ºæ€§",
         "text": [
          "0.84",
          "0.91",
          "0.72",
          "0.70"
         ],
         "textposition": "inside",
         "type": "bar",
         "x": [
          "high quality paper",
          "medium quality report",
          "low quality text",
          "technical documentation"
         ],
         "y": [
          0.8431372549019608,
          0.9083969465648856,
          0.719626168224299,
          0.7
         ]
        },
        {
         "name": "å®Œæ•´æ€§",
         "text": [
          "0.92",
          "0.76",
          "0.56",
          "0.73"
         ],
         "textposition": "inside",
         "type": "bar",
         "x": [
          "high quality paper",
          "medium quality report",
          "low quality text",
          "technical documentation"
         ],
         "y": [
          0.9198955018768341,
          0.7618591136409116,
          0.5555845036913614,
          0.72944016382714
         ]
        },
        {
         "name": "ä¸€è‡´æ€§",
         "text": [
          "0.47",
          "0.78",
          "0.67",
          "0.00"
         ],
         "textposition": "inside",
         "type": "bar",
         "x": [
          "high quality paper",
          "medium quality report",
          "low quality text",
          "technical documentation"
         ],
         "y": [
          0.4679677584182303,
          0.776197140870088,
          0.6676726826572916,
          0
         ]
        },
        {
         "name": "æ™‚æ•ˆæ€§",
         "text": [
          "0.65",
          "0.65",
          "0.50",
          "0.65"
         ],
         "textposition": "inside",
         "type": "bar",
         "x": [
          "high quality paper",
          "medium quality report",
          "low quality text",
          "technical documentation"
         ],
         "y": [
          0.6499999999999999,
          0.6499999999999999,
          0.5,
          0.6499999999999999
         ]
        },
        {
         "name": "å¯ç†è§£æ€§",
         "text": [
          "0.38",
          "0.54",
          "0.61",
          "0.31"
         ],
         "textposition": "inside",
         "type": "bar",
         "x": [
          "high quality paper",
          "medium quality report",
          "low quality text",
          "technical documentation"
         ],
         "y": [
          0.38134069351230443,
          0.54386358974359,
          0.6096564619492657,
          0.3064
         ]
        },
        {
         "name": "å¯è¿½æº¯æ€§",
         "text": [
          "0.90",
          "0.20",
          "0.10",
          "0.65"
         ],
         "textposition": "inside",
         "type": "bar",
         "x": [
          "high quality paper",
          "medium quality report",
          "low quality text",
          "technical documentation"
         ],
         "y": [
          0.9,
          0.2,
          0.1,
          0.65
         ]
        }
       ],
       "layout": {
        "barmode": "group",
        "height": 500,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "å„æ–‡æª”å“è³ªç¶­åº¦åˆ†æ•¸æ¯”è¼ƒ"
        },
        "xaxis": {
         "tickangle": -45,
         "title": {
          "text": "æ–‡æª”"
         }
        },
        "yaxis": {
         "title": {
          "text": "å“è³ªåˆ†æ•¸"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           "blue",
           "orange",
           "orange",
           "orange"
          ]
         },
         "text": [
          "0.713<br>good",
          "0.660<br>fair",
          "0.537<br>fair",
          "0.527<br>fair"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          "high quality paper",
          "medium quality report",
          "low quality text",
          "technical documentation"
         ],
         "y": [
          0.7125028191453392,
          0.6595603216332112,
          0.5366415060741158,
          0.526848032765428
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "å„ªç§€ (>0.9)",
          "x": 1,
          "xanchor": "right",
          "xref": "x domain",
          "y": 0.9,
          "yanchor": "bottom",
          "yref": "y"
         },
         {
          "showarrow": false,
          "text": "è‰¯å¥½ (>0.7)",
          "x": 1,
          "xanchor": "right",
          "xref": "x domain",
          "y": 0.7,
          "yanchor": "bottom",
          "yref": "y"
         },
         {
          "showarrow": false,
          "text": "æ™®é€š (>0.5)",
          "x": 1,
          "xanchor": "right",
          "xref": "x domain",
          "y": 0.5,
          "yanchor": "bottom",
          "yref": "y"
         }
        ],
        "height": 500,
        "shapes": [
         {
          "line": {
           "color": "green",
           "dash": "dash"
          },
          "type": "line",
          "x0": 0,
          "x1": 1,
          "xref": "x domain",
          "y0": 0.9,
          "y1": 0.9,
          "yref": "y"
         },
         {
          "line": {
           "color": "blue",
           "dash": "dash"
          },
          "type": "line",
          "x0": 0,
          "x1": 1,
          "xref": "x domain",
          "y0": 0.7,
          "y1": 0.7,
          "yref": "y"
         },
         {
          "line": {
           "color": "orange",
           "dash": "dash"
          },
          "type": "line",
          "x0": 0,
          "x1": 1,
          "xref": "x domain",
          "y0": 0.5,
          "y1": 0.5,
          "yref": "y"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "æ–‡æª”ç¶œåˆå“è³ªåˆ†æ•¸èˆ‡ç‹€æ…‹"
        },
        "xaxis": {
         "tickangle": -45,
         "title": {
          "text": "æ–‡æª”"
         }
        },
        "yaxis": {
         "range": [
          0,
          1
         ],
         "title": {
          "text": "ç¶œåˆå“è³ªåˆ†æ•¸"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å“è³ªè©•ä¼°è¦–è¦ºåŒ–åœ–è¡¨ç”Ÿæˆå®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“Š ç”Ÿæˆå“è³ªè©•ä¼°è¦–è¦ºåŒ–åœ–è¡¨\\n\")\n",
    "\n",
    "# æº–å‚™è¦–è¦ºåŒ–è³‡æ–™\n",
    "doc_names = [result['filename'].replace('.txt', '').replace('_', ' ') for result in assessment_results]\n",
    "quality_metrics_data = []\n",
    "\n",
    "dimensions = ['accuracy', 'completeness', 'consistency', 'currency', 'understandability', 'traceability']\n",
    "dimension_names = ['æº–ç¢ºæ€§', 'å®Œæ•´æ€§', 'ä¸€è‡´æ€§', 'æ™‚æ•ˆæ€§', 'å¯ç†è§£æ€§', 'å¯è¿½æº¯æ€§']\n",
    "\n",
    "for result in assessment_results:\n",
    "    metrics = result['quality_metrics']\n",
    "    quality_metrics_data.append([\n",
    "        metrics.accuracy,\n",
    "        metrics.completeness,\n",
    "        metrics.consistency,\n",
    "        metrics.currency,\n",
    "        metrics.understandability,\n",
    "        metrics.traceability\n",
    "    ])\n",
    "\n",
    "# 1. é›·é”åœ– - å¤šç¶­åº¦å“è³ªæ¯”è¼ƒ\n",
    "fig = go.Figure()\n",
    "\n",
    "colors = ['blue', 'red', 'green', 'orange']\n",
    "for i, (doc_name, metrics_values) in enumerate(zip(doc_names, quality_metrics_data)):\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=metrics_values + [metrics_values[0]],  # é–‰åˆé›·é”åœ–\n",
    "        theta=dimension_names + [dimension_names[0]],\n",
    "        fill='toself',\n",
    "        name=doc_name,\n",
    "        line_color=colors[i % len(colors)]\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    polar=dict(\n",
    "        radialaxis=dict(\n",
    "            visible=True,\n",
    "            range=[0, 1]\n",
    "        )\n",
    "    ),\n",
    "    showlegend=True,\n",
    "    title=\"æ–‡æª”å“è³ªå¤šç¶­åº¦é›·é”åœ–\",\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# 2. å †ç–ŠæŸ±ç‹€åœ– - å„ç¶­åº¦è²¢ç»\n",
    "fig2 = go.Figure()\n",
    "\n",
    "for i, dim_name in enumerate(dimension_names):\n",
    "    dim_values = [metrics_data[i] for metrics_data in quality_metrics_data]\n",
    "    \n",
    "    fig2.add_trace(go.Bar(\n",
    "        name=dim_name,\n",
    "        x=doc_names,\n",
    "        y=dim_values,\n",
    "        text=[f\"{val:.2f}\" for val in dim_values],\n",
    "        textposition='inside'\n",
    "    ))\n",
    "\n",
    "fig2.update_layout(\n",
    "    barmode='group',\n",
    "    title='å„æ–‡æª”å“è³ªç¶­åº¦åˆ†æ•¸æ¯”è¼ƒ',\n",
    "    xaxis_title='æ–‡æª”',\n",
    "    yaxis_title='å“è³ªåˆ†æ•¸',\n",
    "    height=500,\n",
    "    xaxis_tickangle=-45\n",
    ")\n",
    "\n",
    "fig2.show()\n",
    "\n",
    "# 3. ç¶œåˆå“è³ªåˆ†æ•¸è¶¨å‹¢\n",
    "overall_scores = [result['quality_metrics'].overall_score for result in assessment_results]\n",
    "quality_statuses = [result['quality_status'] for result in assessment_results]\n",
    "\n",
    "# ç‚ºä¸åŒå“è³ªç‹€æ…‹è¨­å®šé¡è‰²\n",
    "status_colors = {\n",
    "    'excellent': 'green',\n",
    "    'good': 'blue', \n",
    "    'fair': 'orange',\n",
    "    'poor': 'red'\n",
    "}\n",
    "\n",
    "colors_mapped = [status_colors.get(status, 'gray') for status in quality_statuses]\n",
    "\n",
    "fig3 = go.Figure()\n",
    "\n",
    "fig3.add_trace(go.Bar(\n",
    "    x=doc_names,\n",
    "    y=overall_scores,\n",
    "    marker_color=colors_mapped,\n",
    "    text=[f\"{score:.3f}<br>{status}\" for score, status in zip(overall_scores, quality_statuses)],\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "# æ·»åŠ å“è³ªé–¾å€¼ç·š\n",
    "fig3.add_hline(y=0.9, line_dash=\"dash\", line_color=\"green\", annotation_text=\"å„ªç§€ (>0.9)\")\n",
    "fig3.add_hline(y=0.7, line_dash=\"dash\", line_color=\"blue\", annotation_text=\"è‰¯å¥½ (>0.7)\")\n",
    "fig3.add_hline(y=0.5, line_dash=\"dash\", line_color=\"orange\", annotation_text=\"æ™®é€š (>0.5)\")\n",
    "\n",
    "fig3.update_layout(\n",
    "    title='æ–‡æª”ç¶œåˆå“è³ªåˆ†æ•¸èˆ‡ç‹€æ…‹',\n",
    "    xaxis_title='æ–‡æª”',\n",
    "    yaxis_title='ç¶œåˆå“è³ªåˆ†æ•¸',\n",
    "    height=500,\n",
    "    xaxis_tickangle=-45,\n",
    "    yaxis=dict(range=[0, 1])\n",
    ")\n",
    "\n",
    "fig3.show()\n",
    "\n",
    "print(\"âœ… å“è³ªè©•ä¼°è¦–è¦ºåŒ–åœ–è¡¨ç”Ÿæˆå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ¸¬è©¦ç•°å¸¸æª¢æ¸¬ç³»çµ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ” æ¸¬è©¦ç•°å¸¸æª¢æ¸¬ç³»çµ±\\n\")\n",
    "\n",
    "# é…ç½®ç•°å¸¸æª¢æ¸¬å™¨\n",
    "anomaly_config = AnomalyDetectionConfig(\n",
    "    method='isolation_forest',\n",
    "    sensitivity=0.15,\n",
    "    min_samples=5,  # ç¾åœ¨æœ‰8å€‹çœŸå¯¦æ–‡æª”ï¼Œæ»¿è¶³æœ€å°æ¨£æœ¬è¦æ±‚\n",
    "    lookback_days=30,\n",
    "    enable_multivariate=True\n",
    ")\n",
    "\n",
    "# åˆå§‹åŒ–ç•°å¸¸æª¢æ¸¬å™¨\n",
    "anomaly_detector = QualityAnomalyDetector(anomaly_config)\n",
    "\n",
    "# æº–å‚™è¨“ç·´è³‡æ–™ï¼ˆå¾8å€‹è©•ä¼°çµæœè½‰æ›ï¼‰\n",
    "training_data = []\n",
    "for result in assessment_results:\n",
    "    metrics = result['quality_metrics']\n",
    "    training_record = {\n",
    "        'document_id': f\"doc_{result['filename']}\",\n",
    "        'assessment_id': f\"assess_{int(datetime.now().timestamp())}_{result['filename']}\",\n",
    "        'accuracy_score': metrics.accuracy,\n",
    "        'completeness_score': metrics.completeness,\n",
    "        'consistency_score': metrics.consistency,\n",
    "        'currency_score': metrics.currency,\n",
    "        'understandability_score': metrics.understandability,\n",
    "        'traceability_score': metrics.traceability,\n",
    "        'overall_score': metrics.overall_score,\n",
    "        'assessed_at': result['assessment_time']\n",
    "    }\n",
    "    training_data.append(training_record)\n",
    "\n",
    "print(f\"ğŸ“Š æº–å‚™äº† {len(training_data)} å€‹çœŸå¯¦è¨“ç·´æ¨£æœ¬\")\n",
    "\n",
    "# è¨“ç·´ç•°å¸¸æª¢æ¸¬å™¨\n",
    "print(\"ğŸ”„ è¨“ç·´ç•°å¸¸æª¢æ¸¬å™¨...\")\n",
    "training_success = anomaly_detector.train_detector(training_data)\n",
    "\n",
    "if training_success:\n",
    "    print(\"âœ… ç•°å¸¸æª¢æ¸¬å™¨è¨“ç·´æˆåŠŸ\\n\")\n",
    "    \n",
    "    # å»ºç«‹ç•°å¸¸æ¸¬è©¦è³‡æ–™\n",
    "    print(\"ğŸ“Š å»ºç«‹ç•°å¸¸æ¸¬è©¦è³‡æ–™...\")\n",
    "    \n",
    "    # å‰µå»ºä¸€äº›ç•°å¸¸çš„å“è³ªè¨˜éŒ„\n",
    "    anomalous_data = [\n",
    "        # æ¥µä½å“è³ªæ–‡æª”\n",
    "        {\n",
    "            'document_id': 'anomaly_doc_1',\n",
    "            'assessment_id': 'assess_anomaly_1',\n",
    "            'accuracy_score': 0.1,  # æ¥µä½\n",
    "            'completeness_score': 0.2,\n",
    "            'consistency_score': 0.15,\n",
    "            'currency_score': 0.3,\n",
    "            'understandability_score': 0.1,\n",
    "            'traceability_score': 0.0,\n",
    "            'overall_score': 0.15,\n",
    "            'assessed_at': datetime.now()\n",
    "        },\n",
    "        # æŸå€‹ç¶­åº¦ç•°å¸¸é«˜\n",
    "        {\n",
    "            'document_id': 'anomaly_doc_2',\n",
    "            'assessment_id': 'assess_anomaly_2', \n",
    "            'accuracy_score': 1.0,  # ç•°å¸¸å®Œç¾\n",
    "            'completeness_score': 0.98,\n",
    "            'consistency_score': 1.0,\n",
    "            'currency_score': 0.95,\n",
    "            'understandability_score': 1.0,\n",
    "            'traceability_score': 1.0,\n",
    "            'overall_score': 0.985,\n",
    "            'assessed_at': datetime.now()\n",
    "        },\n",
    "        # ç¶­åº¦é–“å·®ç•°æ¥µå¤§\n",
    "        {\n",
    "            'document_id': 'anomaly_doc_3',\n",
    "            'assessment_id': 'assess_anomaly_3',\n",
    "            'accuracy_score': 0.9,\n",
    "            'completeness_score': 0.1,  # æ¥µä½\n",
    "            'consistency_score': 0.85,\n",
    "            'currency_score': 0.02,   # æ¥µä½\n",
    "            'understandability_score': 0.75,\n",
    "            'traceability_score': 0.8,\n",
    "            'overall_score': 0.57,\n",
    "            'assessed_at': datetime.now()\n",
    "        },\n",
    "        # ç•°å¸¸ä½çš„æ‰€æœ‰ç¶­åº¦\n",
    "        {\n",
    "            'document_id': 'anomaly_doc_4',\n",
    "            'assessment_id': 'assess_anomaly_4',\n",
    "            'accuracy_score': 0.05,\n",
    "            'completeness_score': 0.08,\n",
    "            'consistency_score': 0.03,\n",
    "            'currency_score': 0.12,\n",
    "            'understandability_score': 0.06,\n",
    "            'traceability_score': 0.02,\n",
    "            'overall_score': 0.06,\n",
    "            'assessed_at': datetime.now()\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # åŠ å…¥æ­£å¸¸è³‡æ–™ä½œç‚ºå°ç…§ï¼ˆä½¿ç”¨çœŸå¯¦è©•ä¼°çµæœçš„å­é›†ï¼‰\n",
    "    test_data = training_data.copy() + anomalous_data\n",
    "    \n",
    "    # åŸ·è¡Œç•°å¸¸æª¢æ¸¬\n",
    "    print(\"ğŸ” åŸ·è¡Œç•°å¸¸æª¢æ¸¬...\")\n",
    "    detected_anomalies = anomaly_detector.detect_anomalies(test_data)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ç•°å¸¸æª¢æ¸¬çµæœ: ç™¼ç¾ {len(detected_anomalies)} å€‹ç•°å¸¸\\n\")\n",
    "    \n",
    "    # é¡¯ç¤ºæª¢æ¸¬åˆ°çš„ç•°å¸¸\n",
    "    for i, anomaly in enumerate(detected_anomalies, 1):\n",
    "        print(f\"ç•°å¸¸ {i}:\")\n",
    "        print(f\"  æ–‡æª”ID: {anomaly.get('document_id')}\")\n",
    "        print(f\"  ç•°å¸¸åˆ†æ•¸: {anomaly.get('anomaly_score', 0):.3f}\")\n",
    "        print(f\"  æª¢æ¸¬æ–¹æ³•: {anomaly.get('detection_method')}\")\n",
    "        print(f\"  æª¢æ¸¬æ™‚é–“: {anomaly.get('detected_at')}\")\n",
    "        \n",
    "        details = anomaly.get('details', {})\n",
    "        if details:\n",
    "            print(f\"  åš´é‡ç¨‹åº¦: {details.get('severity', 'unknown')}\")\n",
    "            if 'affected_dimensions' in details:\n",
    "                print(f\"  å½±éŸ¿ç¶­åº¦: {', '.join(details['affected_dimensions'])}\")\n",
    "            if 'explanation' in details:\n",
    "                for explanation in details['explanation']:\n",
    "                    print(f\"  èªªæ˜: {explanation}\")\n",
    "        print()\n",
    "    \n",
    "    # ç•°å¸¸æª¢æ¸¬æ•ˆæœåˆ†æ\n",
    "    print(\"ğŸ“ˆ ç•°å¸¸æª¢æ¸¬æ•ˆæœåˆ†æ:\")\n",
    "    \n",
    "    # çµ±è¨ˆçœŸå¯¦æ–‡æª”vsç•°å¸¸æ¨£æœ¬çš„æª¢æ¸¬çµæœ\n",
    "    real_doc_anomalies = [a for a in detected_anomalies if a.get('document_id', '').startswith('doc_')]\n",
    "    synthetic_anomalies = [a for a in detected_anomalies if a.get('document_id', '').startswith('anomaly_')]\n",
    "    \n",
    "    print(f\"  çœŸå¯¦æ–‡æª”ä¸­æª¢æ¸¬åˆ°ç•°å¸¸: {len(real_doc_anomalies)} å€‹\")\n",
    "    print(f\"  åˆæˆç•°å¸¸æ¨£æœ¬ä¸­æª¢æ¸¬åˆ°: {len(synthetic_anomalies)} å€‹ (å…±4å€‹ç•°å¸¸æ¨£æœ¬)\")\n",
    "    print(f\"  ç•°å¸¸æª¢æ¸¬æº–ç¢ºç‡: {len(synthetic_anomalies)/4*100:.1f}%\")\n",
    "    \n",
    "    if real_doc_anomalies:\n",
    "        print(f\"  çœŸå¯¦æ–‡æª”ç•°å¸¸è©³æƒ…:\")\n",
    "        for anomaly in real_doc_anomalies:\n",
    "            doc_id = anomaly.get('document_id', '').replace('doc_', '').replace('.txt', '')\n",
    "            print(f\"    - {doc_id}: åˆ†æ•¸ {anomaly.get('anomaly_score', 0):.3f}\")\n",
    "    \n",
    "    # æª¢æ¸¬å™¨çµ±è¨ˆè³‡è¨Š\n",
    "    detector_stats = anomaly_detector.get_detector_stats()\n",
    "    print(\"\\nğŸ“ˆ æª¢æ¸¬å™¨çµ±è¨ˆè³‡è¨Š:\")\n",
    "    for key, value in detector_stats.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "        \n",
    "else:\n",
    "    print(\"âŒ ç•°å¸¸æª¢æ¸¬å™¨è¨“ç·´å¤±æ•—\")\n",
    "    print(f\"  åŸå› : éœ€è¦è‡³å°‘ {anomaly_config.min_samples} å€‹æ¨£æœ¬ï¼Œä½†åªæœ‰ {len(training_data)} å€‹\")\n",
    "\n",
    "print(\"\\nğŸ‰ å“è³ªæ§åˆ¶ç³»çµ±æ¸¬è©¦å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ å­¸ç¿’ç¸½çµèˆ‡ä¸‹ä¸€æ­¥\n",
    "\n",
    "### æ¨¡çµ„ 3 å­¸ç¿’æˆæœæª¢æ ¸\n",
    "\n",
    "å®Œæˆæœ¬æ¨¡çµ„å¾Œï¼Œæ‚¨å·²ç¶“æŒæ¡äº†ï¼š\n",
    "\n",
    "âœ… **å¤šç¶­åº¦å“è³ªè©•ä¼°æ¡†æ¶**\n",
    "- åŸºæ–¼ ISO 25012 æ¨™æº–çš„å…­å¤§å“è³ªç¶­åº¦\n",
    "- æº–ç¢ºæ€§ã€å®Œæ•´æ€§ã€ä¸€è‡´æ€§è©•ä¼°ç®—æ³•\n",
    "- æ™‚æ•ˆæ€§ã€å¯ç†è§£æ€§ã€å¯è¿½æº¯æ€§è©•ä¼°\n",
    "- åŠ æ¬Šç¶œåˆè©•åˆ†æ©Ÿåˆ¶\n",
    "\n",
    "âœ… **è‡ªå‹•åŒ–å“è³ªç›£æ§ç³»çµ±**\n",
    "- å³æ™‚å“è³ªè©•ä¼°èˆ‡ç‹€æ…‹åˆ†é¡\n",
    "- å“è³ªè¶¨å‹¢åˆ†æèˆ‡æ­·å²è¿½è¹¤\n",
    "- å¤šå±¤æ¬¡å“è³ªé–¾å€¼ç®¡ç†\n",
    "- å“è³ªå ±å‘Šè‡ªå‹•ç”Ÿæˆ\n",
    "\n",
    "âœ… **æ™ºèƒ½ç•°å¸¸æª¢æ¸¬æŠ€è¡“**\n",
    "- çµ±è¨ˆç•°å¸¸æª¢æ¸¬ï¼ˆZ-Scoreï¼‰\n",
    "- æ©Ÿå™¨å­¸ç¿’ç•°å¸¸æª¢æ¸¬ï¼ˆIsolation Forestã€One-Class SVMï¼‰\n",
    "- å¤šè®Šé‡ç•°å¸¸æª¢æ¸¬\n",
    "- ç•°å¸¸åš´é‡ç¨‹åº¦è©•ä¼°èˆ‡åˆ†é¡\n",
    "\n",
    "âœ… **å“è³ªæ²»ç†æœ€ä½³å¯¦è¸**\n",
    "- å“è³ªè¦å‰‡å¼•æ“è¨­è¨ˆ\n",
    "- å“è³ªè©•ä¼°çµæœè¦–è¦ºåŒ–\n",
    "- ç•°å¸¸è™•ç†å·¥ä½œæµç¨‹\n",
    "- æŒçºŒæ”¹é€²æ©Ÿåˆ¶\n",
    "\n",
    "### é—œéµæŠ€è¡“äº®é»\n",
    "\n",
    "1. **å…¨é¢çš„å“è³ªæ¨¡å‹**: æ¶µè“‹æ–‡æœ¬å“è³ªçš„å„å€‹å±¤é¢\n",
    "2. **æ™ºèƒ½åŒ–è©•ä¼°**: çµåˆ NLP æŠ€è¡“å’Œçµ±è¨ˆæ–¹æ³•\n",
    "3. **å¯æ“´å±•æ¶æ§‹**: æ”¯æŒè‡ªè¨‚å“è³ªè¦å‰‡å’Œæ¬Šé‡\n",
    "4. **å¯¦æ™‚ç›£æ§**: å³æ™‚æª¢æ¸¬å“è³ªè®ŠåŒ–å’Œç•°å¸¸\n",
    "5. **å¯è¦–åŒ–åˆ†æ**: ç›´è§€å±•ç¤ºå“è³ªè¶¨å‹¢å’Œå•é¡Œ\n",
    "\n",
    "### å¯¦éš›æ‡‰ç”¨å ´æ™¯\n",
    "\n",
    "- **ä¼æ¥­æ–‡æª”ç®¡ç†**: ç¢ºä¿å…§éƒ¨æ–‡æª”çš„ä¸€è‡´æ€§å’Œå“è³ª\n",
    "- **å­¸è¡“è«–æ–‡å¯©æŸ¥**: è‡ªå‹•åŒ–çš„è«–æ–‡å“è³ªåˆå¯©\n",
    "- **å…§å®¹å“è³ªç›£æ§**: ç¶²ç«™å…§å®¹ã€ç”¢å“æ–‡æª”å“è³ªæŠŠé—œ\n",
    "- **åˆè¦æ€§æª¢æŸ¥**: æ–‡æª”æ˜¯å¦ç¬¦åˆè¡Œæ¥­æ¨™æº–å’Œæ³•è¦è¦æ±‚\n",
    "\n",
    "### ä¸‹ä¸€æ­¥å­¸ç¿’å»ºè­°\n",
    "\n",
    "æº–å‚™é€²å…¥ **æ¨¡çµ„ 4: ç«¯åˆ°ç«¯æ•´åˆæ¼”ç¤º**ï¼Œå°‡å­¸ç¿’ï¼š\n",
    "\n",
    "1. **å®Œæ•´ç³»çµ±æ•´åˆ** - çµåˆå‰ä¸‰å€‹æ¨¡çµ„å»ºç«‹å®Œæ•´çš„æ²»ç†ç³»çµ±\n",
    "2. **ç”Ÿç”¢ç´šéƒ¨ç½²** - Docker å®¹å™¨åŒ–ã€API æœå‹™åŒ–\n",
    "3. **æ€§èƒ½å„ªåŒ–** - å¤§è¦æ¨¡æ–‡æª”è™•ç†çš„æ€§èƒ½èª¿å„ª\n",
    "4. **ç›£æ§èˆ‡é‹ç¶­** - ç³»çµ±å¥åº·æª¢æŸ¥ã€æ—¥èªŒåˆ†æã€å‘Šè­¦æ©Ÿåˆ¶\n",
    "\n",
    "æ­å–œå®Œæˆå“è³ªæ§åˆ¶ç³»çµ±çš„å­¸ç¿’ï¼ğŸ‰ æ‚¨ç¾åœ¨æ“æœ‰äº†å»ºç«‹ä¼æ¥­ç´šæ–‡æª”å“è³ªç®¡ç†ç³»çµ±çš„å®Œæ•´æŠ€èƒ½ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
